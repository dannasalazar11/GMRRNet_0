{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dannasalazar11/eegnet-results?scriptVersionId=185632036\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **EEGNet cross-validation**","metadata":{}},{"cell_type":"markdown","source":"En este cuaderno hacemos cross-validation de todos los sujetos de la EEGNet para poder hacer un marco comparativo con la GMRRNet.","metadata":{}},{"cell_type":"markdown","source":"## **Instalación de repositorios e importación de librerías**","metadata":{}},{"cell_type":"code","source":"!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T20:42:29.471239Z","iopub.execute_input":"2024-06-26T20:42:29.47167Z","iopub.status.idle":"2024-06-26T20:43:54.948361Z","shell.execute_reply.started":"2024-06-26T20:42:29.471637Z","shell.execute_reply":"2024-06-26T20:43:54.947432Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gcpds.databases import GIGA_MI_ME\nfrom typing import Optional, Sequence, Tuple\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D\nfrom tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import SpatialDropout2D\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.constraints import max_norm\nimport tensorflow as tf\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom gcpds.visualizations.connectivities import CircosConnectivity\nfrom gcpds.visualizations.topoplots import topoplot\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom keras_tuner import HyperModel, RandomSearch, Objective\nfrom IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:43:54.950341Z","iopub.execute_input":"2024-06-26T20:43:54.950653Z","iopub.status.idle":"2024-06-26T20:44:11.629444Z","shell.execute_reply.started":"2024-06-26T20:43:54.950624Z","shell.execute_reply":"2024-06-26T20:44:11.628705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Funciones usadas para el entrenamiento**","metadata":{}},{"cell_type":"code","source":"#from MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\ndef load_GIGA(db: GIGA_MI_ME,\n              sbj: int,\n              eeg_ch_names: Sequence[str],\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    This function loads the GIGA-Science dataset locally.\n    \n    Parameters\n    ----------\n    db: GIGA_MI_ME\n        A GIGA_MI_ME object created by the gcpds.databases.GIGA_MI_ME module\n    sbj: int\n        The subject to load\n    eeg_ch_names: Sequence[str]\n        The EEG channel names in order\n    fs: float\n        The sampling frecuency\n    f_bank: np.ndarray\n        The frecuency range(s) to use\n    vwt: np.ndarray\n        The time window to load\n    new_fs: float\n        The new sampling frecuency to resample the data to\n    \n    Returns\n    ----------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing the EEG signals for each trial and the corresponding label\n    \n    Notes\n    ----------\n    The database description can be found here:\n    https://academic.oup.com/gigascience/article/6/7/gix034/3796323\n    \"\"\"\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    #print(np.mean (X), np.var(X))\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:44:11.630625Z","iopub.execute_input":"2024-06-26T20:44:11.631325Z","iopub.status.idle":"2024-06-26T20:44:11.641204Z","shell.execute_reply.started":"2024-06-26T20:44:11.631289Z","shell.execute_reply":"2024-06-26T20:44:11.640289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\nfs = db.metadata['sampling_rate']\neeg_ch_names = ['Fp1','Fpz','Fp2',\n              'AF7','AF3','AFz','AF4','AF8',\n              'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n              'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n              'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n              'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n              'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n              'PO7','PO3','POz','PO4','PO8',\n              'O1','Oz','O2',\n              'Iz']\nload_args = dict(db = db,\n                 eeg_ch_names = eeg_ch_names,\n                 fs = fs,\n                 f_bank = np.asarray([[4., 40.]]),\n                 vwt = np.asarray([[2.5, 5]]),\n                 new_fs = 128.)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:44:11.642804Z","iopub.execute_input":"2024-06-26T20:44:11.643536Z","iopub.status.idle":"2024-06-26T20:44:11.659222Z","shell.execute_reply.started":"2024-06-26T20:44:11.6435Z","shell.execute_reply":"2024-06-26T20:44:11.65851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n    \"\"\"\n    Apply digital butterworth filter\n    INPUT\n    ------\n    1. X: (D array)\n    array with signals.\n    2. N: (int+)\n    The order of the filter.\n    3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n    4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n    The type of filter\n    5. fs: (float+)\n    The sampling frequency of the digital system.\n    6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n    7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n    8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n    9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n    10. irlen: (int) or None, Default=nONE\n    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n    OUTPUT\n    ------\n    X_fil: (D array)\n    array with filtered signals.\n    \"\"\"\n    b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n    return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Time frequency representation of EEG signals.\n\n    Parameters\n    ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n    Methods\n    -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n    \"\"\"\n    def __init__(self, sfreq, f_bank=None, vwt=None):\n        self.sfreq = sfreq\n        self.f_bank = f_bank\n        self.vwt = vwt\n    # ------------------------------------------------------------------------------\n\n    def _validation_param(self):\n        \"\"\"\n        Validate Time-Frequency characterization parameters.\n        INPUT\n        -----\n          1. self\n        ------\n          2. None\n        \"\"\"\n        if self.sfreq <= 0:\n            raise ValueError('Non negative sampling frequency is accepted')\n\n\n        if self.f_bank is None:\n            self.flag_f_bank = False\n        elif self.f_bank.ndim != 2:\n            raise ValueError('Band frequencies have to be a 2D array')\n        else:\n            self.flag_f_bank = True\n\n        if self.vwt is None:\n            self.flag_vwt = False\n        elif self.vwt.ndim != 2:\n            raise ValueError('Time windows have to be a 2D array')\n        else:\n            self.flag_vwt = True\n\n    # ------------------------------------------------------------------------------\n    def _filter_bank(self, X):\n        \"\"\"\n        Filter bank Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n        \"\"\"\n        X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n        for f in np.arange(self.f_bank.shape[0]):\n            X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n        return X_f\n\n    # ------------------------------------------------------------------------------\n    def _sliding_windows(self, X):\n        \"\"\"\n        Sliding Windows Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n        \"\"\"\n        window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n        X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n        for w in np.arange(self.vwt.shape[0]):\n            X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n        return X_w\n\n    # ------------------------------------------------------------------------------\n    def fit(self, X, y=None):\n        \"\"\"\n        fit.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n          2. y: (1D array) target labels. Default=None\n        OUTPUT\n        ------\n          1. None\n        \"\"\"\n        pass\n\n    # ------------------------------------------------------------------------------\n    def transform(self, X, y=None):\n        \"\"\"\n        Time frequency representation of EEG signals.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n        OUTPUT\n        ------\n          1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n        \"\"\"\n        self._validation_param()     #Validate sfreq, f_freq, vwt\n\n        #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n        if self.flag_f_bank:\n            X_f = self._filter_bank(X)\n        else:\n            X_f = X[:,:,:,np.newaxis]\n\n        if self.flag_vwt:\n            X_wf = []\n            for f in range(X_f.shape[3]):\n                X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n            X_wf = np.stack(X_wf, axis=-1)\n        else:\n            X_wf = X_f[:,:,:,np.newaxis,:]\n        return X_wf","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:44:11.661261Z","iopub.execute_input":"2024-06-26T20:44:11.661576Z","iopub.status.idle":"2024-06-26T20:44:11.68444Z","shell.execute_reply.started":"2024-06-26T20:44:11.661553Z","shell.execute_reply":"2024-06-26T20:44:11.683641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def EEGNet(nb_classes, Chans = 64, Samples = 128, \n             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n    \"\"\" Keras Implementation of EEGNet\n    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n    Note that this implements the newest version of EEGNet and NOT the earlier\n    version (version v1 and v2 on arxiv). We strongly recommend using this\n    architecture as it performs much better and has nicer properties than\n    our earlier version. For example:\n        \n        1. Depthwise Convolutions to learn spatial filters within a \n        temporal convolution. The use of the depth_multiplier option maps \n        exactly to the number of spatial filters learned within a temporal\n        filter. This matches the setup of algorithms like FBCSP which learn \n        spatial filters within each filter in a filter-bank. This also limits \n        the number of free parameters to fit when compared to a fully-connected\n        convolution. \n        \n        2. Separable Convolutions to learn how to optimally combine spatial\n        filters across temporal bands. Separable Convolutions are Depthwise\n        Convolutions followed by (1x1) Pointwise Convolutions. \n        \n    \n    While the original paper used Dropout, we found that SpatialDropout2D \n    sometimes produced slightly better results for classification of ERP \n    signals. However, SpatialDropout2D significantly reduced performance \n    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n    the default Dropout in most cases.\n        \n    Assumes the input signal is sampled at 128Hz. If you want to use this model\n    for any other sampling rate you will need to modify the lengths of temporal\n    kernels and average pooling size in blocks 1 and 2 as needed (double the \n    kernel lengths for double the sampling rate, etc). Note that we haven't \n    tested the model performance with this rule so this may not work well. \n    \n    The model with default parameters gives the EEGNet-8,2 model as discussed\n    in the paper. This model should do pretty well in general, although it is\n\tadvised to do some model searching to get optimal performance on your\n\tparticular dataset.\n    We set F2 = F1 * D (number of input filters = number of output filters) for\n    the SeparableConv2D layer. We haven't extensively tested other values of this\n    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n    overcomplete). We believe the main parameters to focus on are F1 and D. \n    Inputs:\n        \n      nb_classes      : int, number of classes to classify\n      Chans, Samples  : number of channels and time points in the EEG data\n      dropoutRate     : dropout fraction\n      kernLength      : length of temporal convolution in first layer. We found\n                        that setting this to be half the sampling rate worked\n                        well in practice. For the SMR dataset in particular\n                        since the data was high-passed at 4Hz we used a kernel\n                        length of 32.     \n      F1, F2          : number of temporal filters (F1) and number of pointwise\n                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n      D               : number of spatial filters to learn within each temporal\n                        convolution. Default: D = 2\n      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n    \"\"\"\n    \n    if dropoutType == 'SpatialDropout2D':\n        dropoutType = SpatialDropout2D\n    elif dropoutType == 'Dropout':\n        dropoutType = Dropout\n    else:\n        raise ValueError('dropoutType must be one of SpatialDropout2D '\n                         'or Dropout, passed as a string.')\n    \n    input1   = Input(shape = (Chans, Samples, 1))\n\n    ##################################################################\n    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n                                   name='Conv2D_1',\n                                   input_shape = (Chans, Samples, 1),\n                                   use_bias = False)(input1)\n    block1       = BatchNormalization()(block1)\n    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n                                   name='Depth_wise_Conv2D_1',\n                                   depth_multiplier = D,\n                                   depthwise_constraint = max_norm(1.))(block1)\n    block1       = BatchNormalization()(block1)\n    block1       = Activation('elu')(block1)\n    block1       = AveragePooling2D((1, 4))(block1)\n    block1       = dropoutType(dropoutRate)(block1)\n    \n    block2       = SeparableConv2D(F2, (1, 16),\n                                   name='Separable_Conv2D_1',\n                                   use_bias = False, padding = 'same')(block1) # factorización para que sea más eficiente\n    block2       = BatchNormalization()(block2)\n    block2       = Activation('elu')(block2)\n    block2       = AveragePooling2D((1, 8))(block2)\n    block2       = dropoutType(dropoutRate)(block2)\n        \n    flatten      = Flatten(name = 'flatten')(block2)\n    \n    dense        = Dense(nb_classes, name = 'output', \n                         kernel_constraint = max_norm(norm_rate))(flatten)\n    softmax      = Activation('softmax', name = 'out_activation')(dense)\n    \n    return Model(inputs=input1, outputs=softmax)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:44:11.685709Z","iopub.execute_input":"2024-06-26T20:44:11.685994Z","iopub.status.idle":"2024-06-26T20:44:11.701969Z","shell.execute_reply.started":"2024-06-26T20:44:11.685971Z","shell.execute_reply":"2024-06-26T20:44:11.701096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CV_giga(sbj, results_df):\n    \"\"\"\n    Realiza la validación cruzada en los datos de EEG de un sujeto específico utilizando el modelo EEGNet.\n\n    La función entrena un modelo EEGNet para clasificar señales EEG en una tarea de clasificación binaria.\n    Se utiliza validación cruzada con 5 pliegues (folds) para evaluar la precisión del modelo. Los resultados\n    de cada pliegue se agregan para calcular la precisión promedio y la desviación estándar. Finalmente, los\n    resultados se guardan en un DataFrame.\n\n    Parámetros:\n    -----------\n    sbj : int\n        Identificador del sujeto del que se van a cargar los datos de EEG.\n    results_df : pandas.DataFrame\n        DataFrame en el que se guardan los resultados de la validación cruzada, incluyendo la precisión media\n        y la desviación estándar para cada sujeto.\n\n    Retorna:\n    --------\n    results_df : pandas.DataFrame\n        DataFrame actualizado con los resultados de la validación cruzada para el sujeto actual.\n\n    Descripción del proceso:\n    ------------------------\n    1. Carga de datos:\n       - Se cargan los datos de EEG para el sujeto especificado mediante la función `load_GIGA`.\n       - Las etiquetas (`y`) se transforman a un formato de codificación one-hot.\n\n    2. Configuración de la validación cruzada:\n       - Se utiliza `KFold` para realizar validación cruzada con 5 pliegues, donde los datos se dividen aleatoriamente en\n         5 subconjuntos para entrenamiento y prueba.\n\n    3. Entrenamiento y evaluación del modelo:\n       - En cada pliegue, se entrena un modelo EEGNet con los datos de entrenamiento y se evalúa con los datos de prueba.\n       - Las precisiones de cada pliegue se almacenan en la lista `accuracies`.\n\n    4. Cálculo de resultados:\n       - Se calcula la precisión media y la desviación estándar a partir de los resultados obtenidos en los pliegues.\n\n    5. Almacenamiento de resultados:\n       - Se almacenan la precisión media y la desviación estándar para el sujeto actual en el DataFrame `results_df`.\n    \n    Ejemplo de uso:\n    ---------------\n    # Crear un DataFrame vacío para almacenar resultados\n    results_df = pd.DataFrame(columns=['Subject', 'Mean Accuracy', 'Standard Deviation'])\n\n    # Llamar a la función para un sujeto específico\n    results_df = CV_giga(sbj=1, results_df=results_df)\n    \"\"\"\n    \n    print(\"Training subject\", sbj)\n    X, y = load_GIGA(sbj=sbj, **load_args)\n\n    encoder = OneHotEncoder(sparse_output=True)\n    y = encoder.fit_transform(y.reshape(-1,1)).toarray()\n\n    kfold = KFold(n_splits=5, shuffle=True)\n    accuracies = []\n\n    for train, test in kfold.split(X, y):\n        # Crear el modelo\n        model = EEGNet(2, Samples=320, norm_rate=0.1, kernLength=64)\n        model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n\n        # Entrenar el modelo\n        history = model.fit(X[train], y[train], epochs=150, batch_size=32, verbose=0,\n                            validation_data=(X[test], y[test]))\n\n        # Evaluar el modelo en el fold actual\n        scores = model.evaluate(X[test], y[test], verbose=1)\n        accuracies.append(scores[-1])\n\n    # Calcular la media y desviación estándar\n    mean_accuracy = np.mean(accuracies)\n    std_accuracy = np.std(accuracies)\n\n    # Mostrar resultados de la validación cruzada\n    print(f\"Mean Val Binary Accuracy: {mean_accuracy * 100:.2f}% (+/- {std_accuracy * 100:.2f}%)\")\n\n    # Guardar los resultados en el DataFrame\n    results_df = results_df.append({\n        'Subject': sbj,\n        'Mean Accuracy': mean_accuracy,\n        'Standard Deviation': std_accuracy\n    }, ignore_index=True)\n\n    return results_df","metadata":{"execution":{"iopub.status.busy":"2024-06-26T20:45:40.310771Z","iopub.execute_input":"2024-06-26T20:45:40.311365Z","iopub.status.idle":"2024-06-26T20:45:40.32452Z","shell.execute_reply.started":"2024-06-26T20:45:40.311334Z","shell.execute_reply":"2024-06-26T20:45:40.323534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Cross-validation**","metadata":{}},{"cell_type":"code","source":"# Crear un DataFrame vacío\nresults_df = pd.DataFrame(columns=['Subject', 'Mean Accuracy', 'Standard Deviation'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterar sobre los sujetos y guardar los resultados\nfor sbj in range(1, 29):\n    results_df = CV_giga(sbj, results_df)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-26T20:50:19.277039Z","iopub.execute_input":"2024-06-26T20:50:19.277406Z","iopub.status.idle":"2024-06-26T21:04:26.06515Z","shell.execute_reply.started":"2024-06-26T20:50:19.277376Z","shell.execute_reply":"2024-06-26T21:04:26.063465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterar sobre los sujetos y guardar los resultados\nfor sbj in range(30, 34):\n    results_df = CV_giga(sbj, results_df)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-26T21:04:26.065853Z","iopub.status.idle":"2024-06-26T21:04:26.066196Z","shell.execute_reply.started":"2024-06-26T21:04:26.066031Z","shell.execute_reply":"2024-06-26T21:04:26.066046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sbj in range(35, 53):\n    results_df = CV_giga(sbj, results_df)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-06-26T21:04:26.067387Z","iopub.status.idle":"2024-06-26T21:04:26.067749Z","shell.execute_reply.started":"2024-06-26T21:04:26.067585Z","shell.execute_reply":"2024-06-26T21:04:26.0676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Excel que guarda las medias y las desviaciones estándar** ","metadata":{}},{"cell_type":"code","source":"# Guardar los resultados en un archivo xlsx\nresults_df.to_excel('cross_validation_results_eegnet.xlsx', index=False)\n\n# Mostrar el DataFrame final\nprint(results_df)\n\n# Generar un enlace de descarga para el archivo xlsx\nFileLink('cross_validation_results_eegnet.xlsx')","metadata":{"execution":{"iopub.status.busy":"2024-06-26T21:04:26.069046Z","iopub.status.idle":"2024-06-26T21:04:26.06937Z","shell.execute_reply.started":"2024-06-26T21:04:26.069209Z","shell.execute_reply":"2024-06-26T21:04:26.069223Z"},"trusted":true},"execution_count":null,"outputs":[]}]}