{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d488f0",
   "metadata": {
    "papermill": {
     "duration": 0.005611,
     "end_time": "2024-08-13T17:12:25.799454",
     "exception": false,
     "start_time": "2024-08-13T17:12:25.793843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **GMRRNet cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9608f",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2024-08-13T17:12:25.809574",
     "exception": false,
     "start_time": "2024-08-13T17:12:25.804723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "En este cuaderno hacemos cross-validation para el modelo propuesto, todas las descripciones necesarias están en el cuaderno gmrrnet_functions.ipynb. También es importante importar el dataset \"giga-science-gcpds\" para poder correr estas pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc39ac",
   "metadata": {
    "papermill": {
     "duration": 0.004781,
     "end_time": "2024-08-13T17:12:25.819332",
     "exception": false,
     "start_time": "2024-08-13T17:12:25.814551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Instalamos todos los repositorios e importamos todas las librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93540432",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-13T17:12:25.830462Z",
     "iopub.status.busy": "2024-08-13T17:12:25.830184Z",
     "iopub.status.idle": "2024-08-13T17:13:43.109888Z",
     "shell.execute_reply": "2024-08-13T17:13:43.108924Z"
    },
    "papermill": {
     "duration": 77.288041,
     "end_time": "2024-08-13T17:13:43.112351",
     "exception": false,
     "start_time": "2024-08-13T17:12:25.824310",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/UN-GCPDS/python-gcpds.databases\r\n",
      "  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-vua_2v9k\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-vua_2v9k\r\n",
      "  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit c35637e1a19d7cd21656496339c1dedae6714916\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.11.4)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.7.5)\r\n",
      "Requirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.7.1)\r\n",
      "Requirement already satisfied: tables in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.9.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (4.66.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (2.2.2)\r\n",
      "Collecting gdown (from gcpds-databases==0.2)\r\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (4.12.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (3.13.1)\r\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (2.32.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (5.1.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (3.1.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (0.3)\r\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (1.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.4)\r\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.10.1)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (9.0.0)\r\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.7.0)\r\n",
      "Requirement already satisfied: ndindex>=1.4 in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.8)\r\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.0.7)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->gcpds-databases==0.2) (3.11.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.16.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne->gcpds-databases==0.2) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2024.7.4)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\r\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\r\n",
      "Building wheels for collected packages: gcpds-databases\r\n",
      "  Building wheel for gcpds-databases (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=94504 sha256=eacc61e407957f18f536b9539c9424e696cc43c695e88c3f3a5a2b12e986a837\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-bwpygp34/wheels/8e/66/a7/91b78b1787a3e4d17cb82ea2da67845aa9389012c0ed8280b0\r\n",
      "Successfully built gcpds-databases\r\n",
      "Installing collected packages: gdown, gcpds-databases\r\n",
      "Successfully installed gcpds-databases-0.2 gdown-5.2.0\r\n",
      "Collecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models\r\n",
      "  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to /tmp/pip-req-build-vz48ujuo\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models /tmp/pip-req-build-vz48ujuo\r\n",
      "  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to commit 975885b1f6814fd5958199919b33e02a6a9aa152\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting moabb (from EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading moabb-1.1.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: tensorflow>=2.8 in /opt/conda/lib/python3.10/site-packages (from EEG_Tensorflow_models==0.2) (2.15.0)\r\n",
      "Collecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.7.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.11.4)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.10.0)\r\n",
      "Collecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading skorch-1.0.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (23.5.26)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.4)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (16.0.6)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (69.0.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9.0)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.35.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.60.0)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.0)\r\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow>=2.8->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: PyYAML<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.1)\r\n",
      "Collecting coverage<8.0.0,>=7.0.1 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\r\n",
      "Collecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading edfio-0.4.3-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Collecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.61.0)\r\n",
      "Collecting mne-bids<0.15,>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading mne_bids-0.14-py2.py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Collecting pandas (from braindecode==0.7->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\r\n",
      "Collecting pyriemann<0.7,>=0.6 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading pyriemann-0.6-py2.py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting pytest<8.0.0,>=7.4.0 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (2.32.3)\r\n",
      "Collecting scikit-learn>=1.4.2 (from moabb->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (4.66.4)\r\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.15 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.26.18)\r\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\r\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (9.5.0)\r\n",
      "Requirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.14)\r\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.33.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.42.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (5.9.3)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (5.1.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.3)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2023.3.post1)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (3.11.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyriemann<0.7,>=0.6->moabb->EEG_Tensorflow_models==0.2) (1.4.2)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (2024.7.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->moabb->EEG_Tensorflow_models==0.2) (3.2.0)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.5.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.3)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.2.2)\r\n",
      "Downloading Braindecode-0.7-py3-none-any.whl (184 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading moabb-1.1.0-py3-none-any.whl (230 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.7/230.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.7/234.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading edfio-0.4.3-py3-none-any.whl (25 kB)\r\n",
      "Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\r\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mne_bids-0.14-py2.py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyriemann-0.6-py2.py3-none-any.whl (111 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytest-7.4.4-py3-none-any.whl (325 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\r\n",
      "Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\r\n",
      "  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29376 sha256=c939e22e36cc8f841574e08dfd090b09303ede32898c443860ab90b9695b97f3\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cx3037a8/wheels/05/dc/8a/9d552a33fb901c0d7ab2a72746b5ea17643c570811c711d568\r\n",
      "Successfully built EEG_Tensorflow_models\r\n",
      "Installing collected packages: typeguard, keras, edflib-python, edfio, coverage, tf-keras-vis, tensorflow-addons, scikit-learn, pytest, pandas, skorch, pyriemann, mne-bids, braindecode, moabb, EEG_Tensorflow_models\r\n",
      "  Attempting uninstall: typeguard\r\n",
      "    Found existing installation: typeguard 4.1.5\r\n",
      "    Uninstalling typeguard-4.1.5:\r\n",
      "      Successfully uninstalled typeguard-4.1.5\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.4.1\r\n",
      "    Uninstalling keras-3.4.1:\r\n",
      "      Successfully uninstalled keras-3.4.1\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: pytest\r\n",
      "    Found existing installation: pytest 8.2.2\r\n",
      "    Uninstalling pytest-8.2.2:\r\n",
      "      Successfully uninstalled pytest-8.2.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.2\r\n",
      "    Uninstalling pandas-2.2.2:\r\n",
      "      Successfully uninstalled pandas-2.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.6.1 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.6.1 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\r\n",
      "cudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\r\n",
      "cudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dask-cudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dask-expr 1.1.7 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "rapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "xarray 2024.6.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 coverage-7.6.1 edfio-0.4.3 edflib-python-1.0.8 keras-2.15.0 mne-bids-0.14 moabb-1.1.0 pandas-1.5.3 pyriemann-0.6 pytest-7.4.4 scikit-learn-1.5.1 skorch-1.0.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3\r\n",
      "Collecting git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\r\n",
      "  Cloning https://github.com/UN-GCPDS/python-gcpds.visualizations.git to /tmp/pip-req-build-00w62a_8\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.visualizations.git /tmp/pip-req-build-00w62a_8\r\n",
      "  Resolved https://github.com/UN-GCPDS/python-gcpds.visualizations.git to commit 162dbeac141a7472d3b0bd7f005932241b4663a5\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting python-circos (from gcpds-visualizations==0.6)\r\n",
      "  Downloading python_circos-0.3.0-py3-none-any.whl.metadata (766 bytes)\r\n",
      "Requirement already satisfied: matplotlib>=3.5.3 in /opt/conda/lib/python3.10/site-packages (from gcpds-visualizations==0.6) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gcpds-visualizations==0.6) (1.26.4)\r\n",
      "Requirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from gcpds-visualizations==0.6) (1.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (2.9.0.post0)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (5.1.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (3.1.2)\r\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (0.3)\r\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (1.8.2)\r\n",
      "Requirement already satisfied: scipy>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (1.11.4)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-visualizations==0.6) (4.66.4)\r\n",
      "Collecting biopython>=1.78 (from python-circos->gcpds-visualizations==0.6)\r\n",
      "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (3.11.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (2.32.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne->gcpds-visualizations==0.6) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2024.7.4)\r\n",
      "Downloading python_circos-0.3.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: gcpds-visualizations\r\n",
      "  Building wheel for gcpds-visualizations (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for gcpds-visualizations: filename=gcpds_visualizations-0.6-py3-none-any.whl size=12439 sha256=dab50873e76073d28de530d5dcbb21a21d37b68411847c9068ab556ec7b60155\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iip9auxr/wheels/fa/f8/e8/78c4b4940a8349e29d9199eee5e3c5f526123608864b3834af\r\n",
      "Successfully built gcpds-visualizations\r\n",
      "Installing collected packages: biopython, python-circos, gcpds-visualizations\r\n",
      "Successfully installed biopython-1.84 gcpds-visualizations-0.6 python-circos-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models\n",
    "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c6332f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:43.141404Z",
     "iopub.status.busy": "2024-08-13T17:13:43.141103Z",
     "iopub.status.idle": "2024-08-13T17:13:57.859996Z",
     "shell.execute_reply": "2024-08-13T17:13:57.859064Z"
    },
    "papermill": {
     "duration": 14.736251,
     "end_time": "2024-08-13T17:13:57.862420",
     "exception": false,
     "start_time": "2024-08-13T17:13:43.126169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 17:13:48.620505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-13 17:13:48.620596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-13 17:13:48.755279: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from gcpds.databases import GIGA_MI_ME\n",
    "from gcpds.visualizations.topoplots import topoplot\n",
    "from gcpds.visualizations.connectivities import CircosConnectivity\n",
    "from typing import Optional, Sequence, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.signal import freqz, filtfilt, resample\n",
    "from scipy.signal import butter as bw\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import  Input, Flatten, Dense, Activation, Dropout, concatenate, Layer, Conv2D, AveragePooling2D, SeparableConv2D, DepthwiseConv2D, BatchNormalization, SpatialDropout2D, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.losses import Loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_tuner import HyperModel, RandomSearch, Objective\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4c43b",
   "metadata": {
    "papermill": {
     "duration": 0.013327,
     "end_time": "2024-08-13T17:13:57.889837",
     "exception": false,
     "start_time": "2024-08-13T17:13:57.876510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Todas las funciones necesarias para el funcionamiento del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852649ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:57.919549Z",
     "iopub.status.busy": "2024-08-13T17:13:57.918542Z",
     "iopub.status.idle": "2024-08-13T17:13:58.148572Z",
     "shell.execute_reply": "2024-08-13T17:13:58.147801Z"
    },
    "papermill": {
     "duration": 0.246806,
     "end_time": "2024-08-13T17:13:58.150736",
     "exception": false,
     "start_time": "2024-08-13T17:13:57.903930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_GIGA(db: GIGA_MI_ME,\n",
    "              sbj: int,\n",
    "              eeg_ch_names: Sequence[str],\n",
    "              fs: float, \n",
    "              f_bank: np.ndarray, \n",
    "              vwt: np.ndarray, \n",
    "              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function loads the GIGA-Science dataset locally.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    db: GIGA_MI_ME\n",
    "        A GIGA_MI_ME object created by the gcpds.databases.GIGA_MI_ME module\n",
    "    sbj: int\n",
    "        The subject to load\n",
    "    eeg_ch_names: Sequence[str]\n",
    "        The EEG channel names in order\n",
    "    fs: float\n",
    "        The sampling frecuency\n",
    "    f_bank: np.ndarray\n",
    "        The frecuency range(s) to use\n",
    "    vwt: np.ndarray\n",
    "        The time window to load\n",
    "    new_fs: float\n",
    "        The new sampling frecuency to resample the data to\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        A tuple containing the EEG signals for each trial and the corresponding label\n",
    "    \n",
    "    Notes\n",
    "    ----------\n",
    "    The database description can be found here:\n",
    "    https://academic.oup.com/gigascience/article/6/7/gix034/3796323\n",
    "    \"\"\"\n",
    "    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n",
    "\n",
    "    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
    "\n",
    "    db.load_subject(sbj)\n",
    "    X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n",
    "    X = X[:, index_eeg_chs, :] #spatial rearrangement\n",
    "    X = np.squeeze(tf_repr.transform(X))\n",
    "    #Resampling\n",
    "    if new_fs == fs:\n",
    "        print('No resampling, since new sampling rate same.')\n",
    "    else:\n",
    "        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
    "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
    "\n",
    "    #print(np.mean (X), np.var(X))\n",
    "    return X, y\n",
    "\n",
    "def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n",
    "    \"\"\"\n",
    "    Apply digital butterworth filter\n",
    "    INPUT\n",
    "    ------\n",
    "    1. X: (D array)\n",
    "    array with signals.\n",
    "    2. N: (int+)\n",
    "    The order of the filter.\n",
    "    3. Wn: (float+ or 1D array)\n",
    "    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n",
    "    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n",
    "    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n",
    "    4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n",
    "    The type of filter\n",
    "    5. fs: (float+)\n",
    "    The sampling frequency of the digital system.\n",
    "    6. axis: (int), Default=1.\n",
    "    The axis of x to which the filter is applied.\n",
    "    7. padtype: (str) or None, {'odd', 'even', 'constant'}\n",
    "    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n",
    "    8. padlen: (int+) or None, Default=0\n",
    "    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n",
    "    9. method: (str), {'pad', 'gust'}\n",
    "    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n",
    "    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n",
    "    10. irlen: (int) or None, Default=nONE\n",
    "    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n",
    "    For a long signal, specifying irlen can significantly improve the performance of the filter.\n",
    "    OUTPUT\n",
    "    ------\n",
    "    X_fil: (D array)\n",
    "    array with filtered signals.\n",
    "    \"\"\"\n",
    "    b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n",
    "    return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n",
    "class TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Time frequency representation of EEG signals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    1. sfreq:  (float) Sampling frequency in Hz.\n",
    "    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n",
    "    3. vwt:    (2D array) Interest time windows. Default=None\n",
    "    Methods\n",
    "    -------\n",
    "    1. fit(X, y=None)\n",
    "    2. transform(X, y=None)\n",
    "    \"\"\"\n",
    "    def __init__(self, sfreq, f_bank=None, vwt=None):\n",
    "        self.sfreq = sfreq\n",
    "        self.f_bank = f_bank\n",
    "        self.vwt = vwt\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "    def _validation_param(self):\n",
    "        \"\"\"\n",
    "        Validate Time-Frequency characterization parameters.\n",
    "        INPUT\n",
    "        -----\n",
    "          1. self\n",
    "        ------\n",
    "          2. None\n",
    "        \"\"\"\n",
    "        if self.sfreq <= 0:\n",
    "            raise ValueError('Non negative sampling frequency is accepted')\n",
    "\n",
    "\n",
    "        if self.f_bank is None:\n",
    "            self.flag_f_bank = False\n",
    "        elif self.f_bank.ndim != 2:\n",
    "            raise ValueError('Band frequencies have to be a 2D array')\n",
    "        else:\n",
    "            self.flag_f_bank = True\n",
    "\n",
    "        if self.vwt is None:\n",
    "            self.flag_vwt = False\n",
    "        elif self.vwt.ndim != 2:\n",
    "            raise ValueError('Time windows have to be a 2D array')\n",
    "        else:\n",
    "            self.flag_vwt = True\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    def _filter_bank(self, X):\n",
    "        \"\"\"\n",
    "        Filter bank Characterization.\n",
    "        INPUT\n",
    "        -----\n",
    "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "        OUTPUT\n",
    "        ------\n",
    "          1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n",
    "        \"\"\"\n",
    "        X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n",
    "        for f in np.arange(self.f_bank.shape[0]):\n",
    "            X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n",
    "        return X_f\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    def _sliding_windows(self, X):\n",
    "        \"\"\"\n",
    "        Sliding Windows Characterization.\n",
    "        INPUT\n",
    "        -----\n",
    "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "        OUTPUT\n",
    "        ------\n",
    "          1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n",
    "        \"\"\"\n",
    "        window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n",
    "        X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n",
    "        for w in np.arange(self.vwt.shape[0]):\n",
    "            X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n",
    "        return X_w\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        fit.\n",
    "        INPUT\n",
    "        -----\n",
    "          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
    "          2. y: (1D array) target labels. Default=None\n",
    "        OUTPUT\n",
    "        ------\n",
    "          1. None\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Time frequency representation of EEG signals.\n",
    "        INPUT\n",
    "        -----\n",
    "          1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n",
    "        OUTPUT\n",
    "        ------\n",
    "          1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n",
    "        \"\"\"\n",
    "        self._validation_param()     #Validate sfreq, f_freq, vwt\n",
    "\n",
    "        #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n",
    "        if self.flag_f_bank:\n",
    "            X_f = self._filter_bank(X)\n",
    "        else:\n",
    "            X_f = X[:,:,:,np.newaxis]\n",
    "\n",
    "        if self.flag_vwt:\n",
    "            X_wf = []\n",
    "            for f in range(X_f.shape[3]):\n",
    "                X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n",
    "            X_wf = np.stack(X_wf, axis=-1)\n",
    "        else:\n",
    "            X_wf = X_f[:,:,:,np.newaxis,:]\n",
    "        return X_wf\n",
    "    \n",
    "def plot_training_history(history):\n",
    "    # Extraer datos de history\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_out_activation_loss = history.history['out_activation_loss']\n",
    "    val_out_activation_loss = history.history['val_out_activation_loss']\n",
    "    train_concatenate_2_loss = history.history['concatenated_entropies_loss']\n",
    "    val_concatenate_2_loss = history.history['val_concatenated_entropies_loss']\n",
    "    train_out_activation_acc = history.history['out_activation_binary_accuracy']\n",
    "    val_out_activation_acc = history.history['val_out_activation_binary_accuracy']\n",
    "    epochs = range(1, len(train_loss) + 1)  # Número de épocas\n",
    "\n",
    "    # Graficar pérdida\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training total loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation total loss')\n",
    "    plt.plot(epochs, train_out_activation_loss, 'g', label='Training out_activation_loss')\n",
    "    plt.plot(epochs, val_out_activation_loss, 'm', label='Validation out_activation_loss')\n",
    "    plt.plot(epochs, train_concatenate_2_loss, 'y', label='Training concatenated_entropies_loss')\n",
    "    plt.plot(epochs, val_concatenate_2_loss, 'c', label='Validation concatenated_entropies_loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Graficar precisión\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs, train_out_activation_acc, 'b', label='Training out_activation_binary_accuracy')\n",
    "    plt.plot(epochs, val_out_activation_acc, 'r', label='Validation out_activation_binary_accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9235d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:58.180384Z",
     "iopub.status.busy": "2024-08-13T17:13:58.180109Z",
     "iopub.status.idle": "2024-08-13T17:13:58.187284Z",
     "shell.execute_reply": "2024-08-13T17:13:58.186544Z"
    },
    "papermill": {
     "duration": 0.023583,
     "end_time": "2024-08-13T17:13:58.189224",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.165641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
    "fs = db.metadata['sampling_rate']\n",
    "# 64 canales\n",
    "eeg_ch_names = ['Fp1','Fpz','Fp2',\n",
    "              'AF7','AF3','AFz','AF4','AF8',\n",
    "              'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "              'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
    "              'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
    "              'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
    "              'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
    "              'PO7','PO3','POz','PO4','PO8',\n",
    "              'O1','Oz','O2',\n",
    "              'Iz']\n",
    "load_args = dict(db = db,\n",
    "                 eeg_ch_names = eeg_ch_names,\n",
    "                 fs = fs,\n",
    "                 f_bank = np.asarray([[4., 40.]]), # bandpass\n",
    "                 vwt = np.asarray([[2.5, 5]]),\n",
    "                 new_fs = 128.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a322b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:58.217369Z",
     "iopub.status.busy": "2024-08-13T17:13:58.217116Z",
     "iopub.status.idle": "2024-08-13T17:13:58.242661Z",
     "shell.execute_reply": "2024-08-13T17:13:58.241956Z"
    },
    "papermill": {
     "duration": 0.041803,
     "end_time": "2024-08-13T17:13:58.244441",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.202638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GaussianKernelLayer(Layer):\n",
    "    def __init__(self, sigma=1.0, **kwargs):\n",
    "        super(GaussianKernelLayer, self).__init__(**kwargs)\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GaussianKernelLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs shape: (N, C, T, F)\n",
    "        N, C, T, F = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n",
    "        \n",
    "        # Reshape the input to (N*F, C, T)\n",
    "        inputs = tf.transpose(inputs, perm=(0,3,1,2)) # (N,F,C,T)\n",
    "        inputs_reshaped = tf.reshape(inputs, (N*F, C, T))\n",
    "        \n",
    "        # Calculate the pairwise squared Euclidean distance\n",
    "        squared_differences = tf.expand_dims(inputs_reshaped, axis=2) - tf.expand_dims(inputs_reshaped, axis=1) #(N*F,C,C,T)\n",
    "        squared_differences = tf.square(squared_differences)                                                    #(N*F,C,C,T)\n",
    "        pairwise_distances_squared = tf.reduce_sum(squared_differences, axis=-1)                                #(N*F,C,C)\n",
    "        pairwise_distances_squared = tf.reshape(pairwise_distances_squared, (N,F,C,C))                          #(N,F,C,C)\n",
    "        pairwise_distances_squared = tf.transpose(pairwise_distances_squared, perm=(0,2,3,1))                   #(N,C,C,F)\n",
    "        \n",
    "        # Calculate the Gaussian kernel\n",
    "        gaussian_kernel = tf.exp(-pairwise_distances_squared / (2.0 * tf.square(self.sigma)))\n",
    "        \n",
    "        return gaussian_kernel\n",
    "    \n",
    "def inception_block(x, filters, sigmas):\n",
    "    # Filtros\n",
    "    f1, f2,f3 = filters\n",
    "\n",
    "    # Rama 1: \n",
    "    branch_k1 = GaussianKernelLayer(sigma=sigmas[0], name=\"gaussian_layer_1\")(x)\n",
    "    branch1 = Conv2D(f1, (3, 3), padding='same', activation='relu')(branch_k1)\n",
    "\n",
    "    # Rama 2: \n",
    "    branch_k2 = GaussianKernelLayer(sigma=sigmas[1], name=\"gaussian_layer_2\")(x)\n",
    "    branch2 = Conv2D(f2, (3, 3), padding='same', activation='relu')(branch_k2)\n",
    "\n",
    "    # Rama 3: \n",
    "    branch_k3 = GaussianKernelLayer(sigma=sigmas[2], name=\"gaussian_layer_3\")(x)\n",
    "    branch3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(branch_k3)\n",
    "\n",
    "    # Concatenar las cuatro ramas\n",
    "    output = concatenate([branch1, branch2, branch3], axis=-1)\n",
    "    return branch_k1, branch_k2, branch_k3, output\n",
    "\n",
    "def renyi_entropy(K, alpha=2):\n",
    "        \"\"\"\n",
    "        input: K tensor, (N,F,C,C)\n",
    "        output: NxF\n",
    "        \"\"\"\n",
    "        \n",
    "        C = K.shape[-1]\n",
    "        \n",
    "        # Normalizamos el kernel antes de calcular la entropía\n",
    "        \n",
    "        # Crear una máscara para obtener los elementos diagonales\n",
    "        diag = tf.expand_dims(tf.linalg.diag_part(K), -1)\n",
    "        # Calcular el producto de los elementos diagonales\n",
    "        denominator = tf.math.sqrt(tf.linalg.matmul(diag, diag, transpose_b=True))\n",
    "        # Normalización\n",
    "        \n",
    "        X = (1/C) * tf.math.divide(K, denominator)\n",
    "        \n",
    "        if alpha == 2:\n",
    "            # Realiza el producto matricial entre las dos últimas dimensiones\n",
    "            X_matmul = tf.linalg.matmul(X, X)\n",
    "            return -tf.math.log(tf.linalg.trace(X_matmul))\n",
    "        else:\n",
    "            # Calcula los autovalores y autovectores de las dos últimas dimensiones\n",
    "            e, _ = tf.linalg.eigh(X)\n",
    "            # Calcula la entropía de Renyi\n",
    "            return (tf.math.log(tf.reduce_sum(tf.math.real(tf.math.pow(e, alpha)), axis=-1)) / (1 - alpha))\n",
    "                               \n",
    "def joint_renyi_entropy(K, alpha):\n",
    "        \"\"\"\n",
    "        input: K, (N,F,C,C)\n",
    "        output: Nx1\n",
    "        \"\"\"\n",
    "        \n",
    "        C = K.shape[-1]\n",
    "        product = tf.reduce_prod(K,axis=1) # (N,C,C)\n",
    "        \n",
    "        trace = tf.linalg.trace(product)\n",
    "        trace = tf.expand_dims(tf.expand_dims(trace, axis=-1), axis=-1)\n",
    "        trace = tf.tile(trace, [1,C,C])\n",
    "        \n",
    "        argument = product/trace\n",
    "        argument = tf.expand_dims(argument, axis=1) # es necesario porque renyi_entropy recibe 4 dimensiones (1,C,C)\n",
    "        joint_entropy = renyi_entropy(argument, alpha=alpha)\n",
    "                               \n",
    "        return joint_entropy\n",
    "    \n",
    "class RenyiMutualInformation(Loss):\n",
    "    def __init__(self, C, **kwargs):\n",
    "        self.C = C\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true: \n",
    "        y_pred: N x (F+1) las F entropías marginales y la entropía conjunta\n",
    "        \"\"\"\n",
    "        \n",
    "        F = y_pred.shape[1]-1\n",
    "        entropy,  joint_entropy = tf.split(y_pred, [F,1], axis=-1)\n",
    "        \n",
    "        #Cast todo\n",
    "        entropy = tf.cast(entropy, tf.float64)\n",
    "        joint_entropy = tf.cast(joint_entropy, tf.float64)\n",
    "        log_C = tf.math.log(tf.cast(self.C, tf.float64))\n",
    "        \n",
    "        mutual_information = tf.math.abs((tf.expand_dims(tf.reduce_sum(entropy, axis=-1), axis=-1) - joint_entropy)) / (F * log_C) # normalizado\n",
    "\n",
    "\n",
    "        return mutual_information\n",
    "    \n",
    "# Normalizamos \n",
    "\n",
    "class NormalizedBinaryCrossentropy(Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true: N x 2\n",
    "        y_pred: N x 2 \n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(y_pred)[0]  # batch_size is now an integer tensor\n",
    "        batch_size_float = tf.cast(batch_size, tf.float32)\n",
    "        \n",
    "        cce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        left = tf.tile(tf.expand_dims([1.0, 0.0], axis=0), [batch_size, 1])\n",
    "        right = tf.tile(tf.expand_dims([0.0, 1.0], axis=0), [batch_size, 1])\n",
    "        \n",
    "        cce_left = tf.keras.losses.binary_crossentropy(left, y_pred)\n",
    "        cce_right = tf.keras.losses.binary_crossentropy(right, y_pred)\n",
    "        \n",
    "        cce_norm = tf.divide(cce, (cce_left + cce_right))\n",
    "        \n",
    "        return cce_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac040bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:58.272404Z",
     "iopub.status.busy": "2024-08-13T17:13:58.272164Z",
     "iopub.status.idle": "2024-08-13T17:13:58.286937Z",
     "shell.execute_reply": "2024-08-13T17:13:58.286254Z"
    },
    "papermill": {
     "duration": 0.031316,
     "end_time": "2024-08-13T17:13:58.289175",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.257859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def KernelConvInceptionMI(nb_classes=2, Chans=64, Samples=320, \n",
    "                          kernLength=64, norm_rate=0.25, alpha=2):\n",
    "    \"\"\"\n",
    "    Define un modelo de red neuronal convolucional con bloques de Inception \n",
    "    y capas adicionales para calcular la entropía de Renyi y la información mutua.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    nb_classes : int, opcional (por defecto=2)\n",
    "        Número de clases a clasificar.\n",
    "    Chans : int, opcional (por defecto=64)\n",
    "        Número de canales en los datos de EEG.\n",
    "    Samples : int, opcional (por defecto=320)\n",
    "        Número de muestras en los datos de EEG.\n",
    "    kernLength : int, opcional (por defecto=64)\n",
    "        Longitud del kernel para la primera capa convolucional.\n",
    "    norm_rate : float, opcional (por defecto=0.25)\n",
    "        Tasa de normalización para la capa densa.\n",
    "    alpha : float, opcional (por defecto=2)\n",
    "        Parámetro alpha para calcular la entropía de Renyi y la información mutua.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Modelo compilado de Keras listo para el entrenamiento.\n",
    "\n",
    "    Descripción del modelo:\n",
    "    -----------------------\n",
    "    El modelo `KernelConvInceptionMI` utiliza una combinación de convoluciones 2D, bloques de Inception \n",
    "    y capas personalizadas para calcular medidas de entropía y de información mutua. Este enfoque está diseñado \n",
    "    para extraer características espaciales y temporales de las señales EEG, mientras que las capas de entropía \n",
    "    capturan la complejidad y redundancia en los datos.\n",
    "\n",
    "    1. **Capa de Entrada**:\n",
    "       - `input1`: Entrada principal con forma `(Chans, Samples, 1)`, que representa los datos de EEG.\n",
    "\n",
    "    2. **Primera Convolución 2D**:\n",
    "       - Se aplica una convolución 2D con `F1` filtros y un kernel de longitud `kernLength` a la entrada.\n",
    "\n",
    "    3. **Bloque Inception**:\n",
    "       - El bloque de Inception se compone de tres ramas convolucionales con diferentes valores de sigma (`sigma1`, `sigma2`, `sigma3`).\n",
    "       - Cada rama convolucional extrae características a diferentes escalas.\n",
    "\n",
    "    4. **Cálculo de la Entropía y la Información Mutua**:\n",
    "       - Se concatenan las salidas de las tres ramas convolucionales del bloque de Inception.\n",
    "       - Se calcula la entropía de Renyi (`layer_entropy`) y la entropía conjunta de Renyi (`layer_joint_entropy`) usando capas Lambda personalizadas.\n",
    "       - Las entropías calculadas se concatenan en `concatenate_entropies`.\n",
    "\n",
    "    5. **Convolución Final y Capa Densa**:\n",
    "       - Se aplica una segunda convolución 2D, seguida de una capa de aplanado (`Flatten`).\n",
    "       - Una capa densa con 64 neuronas se conecta a la salida aplanada, seguida de la capa de salida con activación softmax.\n",
    "\n",
    "    6. **Salida del Modelo**:\n",
    "       - El modelo tiene dos salidas: la probabilidad de clasificación (`softmax`) y las entropías concatenadas (`concatenate_entropies`).\n",
    "\n",
    "    7. **Compilación del Modelo**:\n",
    "       - El modelo se compila con el optimizador 'adam' y una pérdida combinada: \n",
    "         `NormalizedBinaryCrossentropy()` para la clasificación y `RenyiMutualInformation()` para la entropía.\n",
    "       - Las métricas incluyen la precisión binaria.\n",
    "\n",
    "    Ejemplo de uso:\n",
    "    ---------------\n",
    "    model = KernelConvInceptionMI(nb_classes=2, Chans=64, Samples=320, \n",
    "                                  kernLength=64, norm_rate=0.25, alpha=2)\n",
    "    model.summary()\n",
    "    \"\"\"\n",
    "    \n",
    "    ######\n",
    "    F1 = 3\n",
    "    F2 = 5\n",
    "    F3 = 3\n",
    "    ######\n",
    "    \n",
    "    input1   = Input(shape=(Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    conv2D = Conv2D(F1, (1, kernLength), padding='same',\n",
    "                    name='Conv2D_1',\n",
    "                    input_shape=(Chans, Samples, 1),\n",
    "                    use_bias=False)(input1)\n",
    "    block1 = BatchNormalization()(conv2D)\n",
    "    \n",
    "    sigma1 = 0.8\n",
    "    sigma2 = 2.2\n",
    "    sigma3 = 4.8\n",
    "\n",
    "    branch_k1, branch_k2, branch_k3, inception = inception_block(block1, [F2, F2, F2], [sigma1, sigma2, sigma3])\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    concatenated_branches = concatenate([branch_k1, branch_k2, branch_k3], axis=-1)\n",
    "    concatenated_branches = tf.transpose(concatenated_branches, perm=(0, 3, 1, 2))\n",
    "    layer_entropy = Lambda(lambda x: renyi_entropy(x, alpha=alpha), name=\"entropy\")(concatenated_branches)\n",
    "    \n",
    "    layer_joint_entropy = Lambda(lambda x: joint_renyi_entropy(x, alpha=alpha), name=\"joint_entropy\")(concatenated_branches)\n",
    "    \n",
    "    concatenate_entropies = concatenate([layer_entropy, layer_joint_entropy], axis=-1, name=\"concatenated_entropies\")\n",
    "    \n",
    "    ###############\n",
    "    conv2D = Conv2D(F3, 3, padding='same',\n",
    "                    name='Conv2D_2')(inception)\n",
    "    \n",
    "    conv2D = BatchNormalization()(conv2D)\n",
    "    flatten = Flatten(name='flatten')(conv2D)\n",
    "    \n",
    "    dense = Dense(64, kernel_constraint=max_norm(norm_rate), activation=\"relu\")(flatten)\n",
    "    dense = Dense(nb_classes, name='output', \n",
    "                  kernel_constraint=max_norm(norm_rate))(dense)\n",
    "    softmax = Activation('softmax', name='out_activation')(dense)\n",
    "    \n",
    "    model = Model(inputs=input1, outputs=[softmax, concatenate_entropies])    \n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=[NormalizedBinaryCrossentropy(), RenyiMutualInformation(C=tf.cast(64.0, tf.float64), name='MutualInfo')], \n",
    "                  loss_weights=[0.8, 0.2], \n",
    "                  metrics=[['binary_accuracy'], [None]])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8c1360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:58.317391Z",
     "iopub.status.busy": "2024-08-13T17:13:58.317152Z",
     "iopub.status.idle": "2024-08-13T17:13:58.331745Z",
     "shell.execute_reply": "2024-08-13T17:13:58.330931Z"
    },
    "papermill": {
     "duration": 0.030691,
     "end_time": "2024-08-13T17:13:58.333537",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.302846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def CV_giga(sbj, results_df):\n",
    "    \"\"\"\n",
    "    Realiza la validación cruzada en los datos de EEG de un sujeto específico utilizando el modelo KernelConvInceptionMI.\n",
    "\n",
    "    La función entrena un modelo KernelConvInceptionMI para clasificar señales EEG en una tarea de clasificación binaria.\n",
    "    Se utiliza validación cruzada con 5 pliegues (folds) para evaluar la precisión del modelo. Los resultados\n",
    "    de cada pliegue se agregan para calcular la precisión promedio y la desviación estándar. Finalmente, los\n",
    "    resultados se guardan en un DataFrame.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    sbj : int\n",
    "        Identificador del sujeto del que se van a cargar los datos de EEG.\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame en el que se guardan los resultados de la validación cruzada, incluyendo la precisión media\n",
    "        y la desviación estándar para cada sujeto.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame actualizado con los resultados de la validación cruzada para el sujeto actual.\n",
    "\n",
    "    Descripción del proceso:\n",
    "    ------------------------\n",
    "    1. Carga de datos:\n",
    "       - Se cargan los datos de EEG para el sujeto especificado mediante la función `load_GIGA`.\n",
    "       - Las etiquetas (`y`) se transforman a un formato de codificación one-hot usando `OneHotEncoder`.\n",
    "\n",
    "    2. Configuración de la validación cruzada:\n",
    "       - Se utiliza `KFold` para realizar validación cruzada con 5 pliegues, donde los datos se dividen aleatoriamente en\n",
    "         5 subconjuntos para entrenamiento y prueba.\n",
    "\n",
    "    3. Entrenamiento y evaluación del modelo:\n",
    "       - En cada pliegue, se entrena un modelo `KernelConvInceptionMI` con los datos de entrenamiento y se evalúa con los datos de prueba.\n",
    "       - Las precisiones de cada pliegue se almacenan en la lista `accuracies`.\n",
    "\n",
    "    4. Cálculo de resultados:\n",
    "       - Se calcula la precisión media y la desviación estándar a partir de los resultados obtenidos en los pliegues.\n",
    "\n",
    "    5. Almacenamiento de resultados:\n",
    "       - Se almacenan la precisión media y la desviación estándar para el sujeto actual en el DataFrame `results_df`.\n",
    "    \n",
    "    Ejemplo de uso:\n",
    "    ---------------\n",
    "    # Crear un DataFrame vacío para almacenar resultados\n",
    "    results_df = pd.DataFrame(columns=['Subject', 'Mean Accuracy', 'Standard Deviation'])\n",
    "\n",
    "    # Llamar a la función para un sujeto específico\n",
    "    results_df = CV_giga(sbj=1, results_df=results_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Training subject\", sbj)\n",
    "    X, y = load_GIGA(sbj=sbj, **load_args)\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=True)\n",
    "    y = encoder.fit_transform(y.reshape(-1,1)).toarray()\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for train, test in kfold.split(X, y):\n",
    "        # Crear el modelo\n",
    "        model = KernelConvInceptionMI()\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        history = model.fit(X[train], y[train], epochs=150, batch_size=32, verbose=0,\n",
    "                            validation_data=(X[test], y[test]))\n",
    "\n",
    "        # Evaluar el modelo en el fold actual\n",
    "        scores = model.evaluate(X[test], y[test], verbose=1)\n",
    "        accuracies.append(scores[-1])\n",
    "\n",
    "    # Calcular la media y desviación estándar\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    # Mostrar resultados de la validación cruzada\n",
    "    print(f\"Mean Val Binary Accuracy: {mean_accuracy * 100:.2f}% (+/- {std_accuracy * 100:.2f}%)\")\n",
    "\n",
    "    # Guardar los resultados en el DataFrame\n",
    "    results_df = results_df.append({\n",
    "        'Subject': sbj,\n",
    "        'Mean Accuracy': mean_accuracy,\n",
    "        'Standard Deviation': std_accuracy\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Crear un DataFrame vacío\n",
    "results_df = pd.DataFrame(columns=['Subject', 'Mean Accuracy', 'Standard Deviation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a01ce",
   "metadata": {
    "papermill": {
     "duration": 0.013291,
     "end_time": "2024-08-13T17:13:58.360135",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.346844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Cross-validation por cada sujeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d7acdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:13:58.388066Z",
     "iopub.status.busy": "2024-08-13T17:13:58.387785Z",
     "iopub.status.idle": "2024-08-13T20:07:10.974621Z",
     "shell.execute_reply": "2024-08-13T20:07:10.973671Z"
    },
    "papermill": {
     "duration": 10392.637555,
     "end_time": "2024-08-13T20:07:11.011201",
     "exception": false,
     "start_time": "2024-08-13T17:13:58.373646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subject 1\n",
      "Resampling from 512.000000 to 128.000000 Hz.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723569250.823715     213 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3953 - out_activation_loss: 0.3451 - concatenated_entropies_loss: 0.5963 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2784 - out_activation_loss: 0.1852 - concatenated_entropies_loss: 0.6513 - out_activation_binary_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3370 - out_activation_loss: 0.2561 - concatenated_entropies_loss: 0.6605 - out_activation_binary_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2846 - out_activation_loss: 0.1942 - concatenated_entropies_loss: 0.6462 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3634 - out_activation_loss: 0.3028 - concatenated_entropies_loss: 0.6057 - out_activation_binary_accuracy: 0.7250\n",
      "Mean Val Binary Accuracy: 75.00% (+/- 8.06%)\n",
      "Training subject 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4658 - out_activation_loss: 0.3983 - concatenated_entropies_loss: 0.7361 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4585 - out_activation_loss: 0.4109 - concatenated_entropies_loss: 0.6490 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4315 - out_activation_loss: 0.3502 - concatenated_entropies_loss: 0.7570 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5771 - out_activation_loss: 0.5304 - concatenated_entropies_loss: 0.7642 - out_activation_binary_accuracy: 0.4750\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5769 - out_activation_loss: 0.5277 - concatenated_entropies_loss: 0.7734 - out_activation_binary_accuracy: 0.4500\n",
      "Mean Val Binary Accuracy: 56.50% (+/- 8.46%)\n",
      "Training subject 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2280 - out_activation_loss: 0.1082 - concatenated_entropies_loss: 0.7072 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1874 - out_activation_loss: 0.0603 - concatenated_entropies_loss: 0.6955 - out_activation_binary_accuracy: 0.9750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2189 - out_activation_loss: 0.1115 - concatenated_entropies_loss: 0.6489 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1716 - out_activation_loss: 0.0546 - concatenated_entropies_loss: 0.6398 - out_activation_binary_accuracy: 0.9500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1641 - out_activation_loss: 0.0251 - concatenated_entropies_loss: 0.7204 - out_activation_binary_accuracy: 0.9750\n",
      "Mean Val Binary Accuracy: 93.50% (+/- 4.06%)\n",
      "Training subject 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2422 - out_activation_loss: 0.1666 - concatenated_entropies_loss: 0.5446 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2863 - out_activation_loss: 0.1794 - concatenated_entropies_loss: 0.7139 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1632 - out_activation_loss: 0.0373 - concatenated_entropies_loss: 0.6667 - out_activation_binary_accuracy: 0.9750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2353 - out_activation_loss: 0.1207 - concatenated_entropies_loss: 0.6936 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2299 - out_activation_loss: 0.1084 - concatenated_entropies_loss: 0.7161 - out_activation_binary_accuracy: 0.9250\n",
      "Mean Val Binary Accuracy: 87.50% (+/- 7.07%)\n",
      "Training subject 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3300 - out_activation_loss: 0.2289 - concatenated_entropies_loss: 0.7344 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3524 - out_activation_loss: 0.2521 - concatenated_entropies_loss: 0.7535 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3653 - out_activation_loss: 0.2847 - concatenated_entropies_loss: 0.6877 - out_activation_binary_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3878 - out_activation_loss: 0.3163 - concatenated_entropies_loss: 0.6741 - out_activation_binary_accuracy: 0.6750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3492 - out_activation_loss: 0.2582 - concatenated_entropies_loss: 0.7131 - out_activation_binary_accuracy: 0.7179\n",
      "Mean Val Binary Accuracy: 73.86% (+/- 4.42%)\n",
      "Training subject 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3596 - out_activation_loss: 0.2813 - concatenated_entropies_loss: 0.6727 - out_activation_binary_accuracy: 0.7222\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3222 - out_activation_loss: 0.2377 - concatenated_entropies_loss: 0.6601 - out_activation_binary_accuracy: 0.7778\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2695 - out_activation_loss: 0.1595 - concatenated_entropies_loss: 0.7096 - out_activation_binary_accuracy: 0.8611\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3125 - out_activation_loss: 0.2457 - concatenated_entropies_loss: 0.5794 - out_activation_binary_accuracy: 0.7429\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3312 - out_activation_loss: 0.2540 - concatenated_entropies_loss: 0.6400 - out_activation_binary_accuracy: 0.7429\n",
      "Mean Val Binary Accuracy: 76.94% (+/- 4.92%)\n",
      "Training subject 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5559 - out_activation_loss: 0.5166 - concatenated_entropies_loss: 0.7130 - out_activation_binary_accuracy: 0.4792\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5361 - out_activation_loss: 0.4866 - concatenated_entropies_loss: 0.7343 - out_activation_binary_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4896 - out_activation_loss: 0.4454 - concatenated_entropies_loss: 0.6664 - out_activation_binary_accuracy: 0.5208\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4036 - out_activation_loss: 0.3405 - concatenated_entropies_loss: 0.6558 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5328 - out_activation_loss: 0.5026 - concatenated_entropies_loss: 0.6539 - out_activation_binary_accuracy: 0.4792\n",
      "Mean Val Binary Accuracy: 52.08% (+/- 5.43%)\n",
      "Training subject 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5032 - out_activation_loss: 0.4569 - concatenated_entropies_loss: 0.6885 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4898 - out_activation_loss: 0.4584 - concatenated_entropies_loss: 0.6155 - out_activation_binary_accuracy: 0.5250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5793 - out_activation_loss: 0.5451 - concatenated_entropies_loss: 0.7163 - out_activation_binary_accuracy: 0.4250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3841 - out_activation_loss: 0.3063 - concatenated_entropies_loss: 0.6955 - out_activation_binary_accuracy: 0.7179\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5348 - out_activation_loss: 0.4986 - concatenated_entropies_loss: 0.6798 - out_activation_binary_accuracy: 0.4615\n",
      "Mean Val Binary Accuracy: 53.59% (+/- 10.13%)\n",
      "Training subject 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4073 - out_activation_loss: 0.3336 - concatenated_entropies_loss: 0.7022 - out_activation_binary_accuracy: 0.7292\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4252 - out_activation_loss: 0.3489 - concatenated_entropies_loss: 0.7302 - out_activation_binary_accuracy: 0.6875\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3711 - out_activation_loss: 0.2785 - concatenated_entropies_loss: 0.7415 - out_activation_binary_accuracy: 0.7292\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4214 - out_activation_loss: 0.3412 - concatenated_entropies_loss: 0.7421 - out_activation_binary_accuracy: 0.6875\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3946 - out_activation_loss: 0.3055 - concatenated_entropies_loss: 0.7509 - out_activation_binary_accuracy: 0.7083\n",
      "Mean Val Binary Accuracy: 70.83% (+/- 1.86%)\n",
      "Training subject 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3315 - out_activation_loss: 0.2535 - concatenated_entropies_loss: 0.6433 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2997 - out_activation_loss: 0.2049 - concatenated_entropies_loss: 0.6791 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3196 - out_activation_loss: 0.2513 - concatenated_entropies_loss: 0.5927 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3141 - out_activation_loss: 0.2338 - concatenated_entropies_loss: 0.6354 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2633 - out_activation_loss: 0.1687 - concatenated_entropies_loss: 0.6419 - out_activation_binary_accuracy: 0.8750\n",
      "Mean Val Binary Accuracy: 80.50% (+/- 4.30%)\n",
      "Training subject 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4955 - out_activation_loss: 0.4471 - concatenated_entropies_loss: 0.6892 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5116 - out_activation_loss: 0.4656 - concatenated_entropies_loss: 0.6954 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6048 - out_activation_loss: 0.5724 - concatenated_entropies_loss: 0.7346 - out_activation_binary_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5497 - out_activation_loss: 0.4961 - concatenated_entropies_loss: 0.7638 - out_activation_binary_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5448 - out_activation_loss: 0.5154 - concatenated_entropies_loss: 0.6628 - out_activation_binary_accuracy: 0.4250\n",
      "Mean Val Binary Accuracy: 51.00% (+/- 9.30%)\n",
      "Training subject 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4474 - out_activation_loss: 0.4014 - concatenated_entropies_loss: 0.6317 - out_activation_binary_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4260 - out_activation_loss: 0.3834 - concatenated_entropies_loss: 0.5963 - out_activation_binary_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3559 - out_activation_loss: 0.3106 - concatenated_entropies_loss: 0.5374 - out_activation_binary_accuracy: 0.6571\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3566 - out_activation_loss: 0.3018 - concatenated_entropies_loss: 0.5758 - out_activation_binary_accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3181 - out_activation_loss: 0.2406 - concatenated_entropies_loss: 0.6283 - out_activation_binary_accuracy: 0.7941\n",
      "Mean Val Binary Accuracy: 67.31% (+/- 7.39%)\n",
      "Training subject 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2196 - out_activation_loss: 0.1403 - concatenated_entropies_loss: 0.5371 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2454 - out_activation_loss: 0.1855 - concatenated_entropies_loss: 0.4852 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2693 - out_activation_loss: 0.1780 - concatenated_entropies_loss: 0.6344 - out_activation_binary_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1980 - out_activation_loss: 0.1151 - concatenated_entropies_loss: 0.5297 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2041 - out_activation_loss: 0.1241 - concatenated_entropies_loss: 0.5245 - out_activation_binary_accuracy: 0.9000\n",
      "Mean Val Binary Accuracy: 88.00% (+/- 3.67%)\n",
      "Training subject 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1158 - out_activation_loss: 0.0031 - concatenated_entropies_loss: 0.5667 - out_activation_binary_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0980 - out_activation_loss: 0.0013 - concatenated_entropies_loss: 0.4849 - out_activation_binary_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1993 - out_activation_loss: 0.0770 - concatenated_entropies_loss: 0.6887 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1685 - out_activation_loss: 0.0661 - concatenated_entropies_loss: 0.5778 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1607 - out_activation_loss: 0.0512 - concatenated_entropies_loss: 0.5988 - out_activation_binary_accuracy: 0.9500\n",
      "Mean Val Binary Accuracy: 96.00% (+/- 3.39%)\n",
      "Training subject 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2814 - out_activation_loss: 0.1844 - concatenated_entropies_loss: 0.6697 - out_activation_binary_accuracy: 0.8205\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3476 - out_activation_loss: 0.2552 - concatenated_entropies_loss: 0.7170 - out_activation_binary_accuracy: 0.7632\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3358 - out_activation_loss: 0.2484 - concatenated_entropies_loss: 0.6852 - out_activation_binary_accuracy: 0.7895\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3193 - out_activation_loss: 0.2143 - concatenated_entropies_loss: 0.7395 - out_activation_binary_accuracy: 0.7895\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3278 - out_activation_loss: 0.2532 - concatenated_entropies_loss: 0.6259 - out_activation_binary_accuracy: 0.7368\n",
      "Mean Val Binary Accuracy: 77.99% (+/- 2.82%)\n",
      "Training subject 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4339 - out_activation_loss: 0.3668 - concatenated_entropies_loss: 0.7022 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4567 - out_activation_loss: 0.3907 - concatenated_entropies_loss: 0.7210 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4967 - out_activation_loss: 0.4460 - concatenated_entropies_loss: 0.6995 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4550 - out_activation_loss: 0.3901 - concatenated_entropies_loss: 0.7146 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4543 - out_activation_loss: 0.3836 - concatenated_entropies_loss: 0.7370 - out_activation_binary_accuracy: 0.6154\n",
      "Mean Val Binary Accuracy: 60.81% (+/- 4.01%)\n",
      "Training subject 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4720 - out_activation_loss: 0.4500 - concatenated_entropies_loss: 0.5604 - out_activation_binary_accuracy: 0.5250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5116 - out_activation_loss: 0.4944 - concatenated_entropies_loss: 0.5801 - out_activation_binary_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4807 - out_activation_loss: 0.4599 - concatenated_entropies_loss: 0.5638 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4266 - out_activation_loss: 0.3881 - concatenated_entropies_loss: 0.5807 - out_activation_binary_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5067 - out_activation_loss: 0.5060 - concatenated_entropies_loss: 0.5096 - out_activation_binary_accuracy: 0.4750\n",
      "Mean Val Binary Accuracy: 53.00% (+/- 4.30%)\n",
      "Training subject 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5075 - out_activation_loss: 0.4549 - concatenated_entropies_loss: 0.7179 - out_activation_binary_accuracy: 0.4750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3490 - out_activation_loss: 0.2542 - concatenated_entropies_loss: 0.7283 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4686 - out_activation_loss: 0.4086 - concatenated_entropies_loss: 0.7083 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4118 - out_activation_loss: 0.3615 - concatenated_entropies_loss: 0.6129 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4423 - out_activation_loss: 0.3739 - concatenated_entropies_loss: 0.7159 - out_activation_binary_accuracy: 0.6000\n",
      "Mean Val Binary Accuracy: 60.50% (+/- 8.86%)\n",
      "Training subject 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4219 - out_activation_loss: 0.3662 - concatenated_entropies_loss: 0.6447 - out_activation_binary_accuracy: 0.6552\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4190 - out_activation_loss: 0.3358 - concatenated_entropies_loss: 0.7517 - out_activation_binary_accuracy: 0.6207\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4677 - out_activation_loss: 0.4104 - concatenated_entropies_loss: 0.6969 - out_activation_binary_accuracy: 0.6552\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3598 - out_activation_loss: 0.2865 - concatenated_entropies_loss: 0.6530 - out_activation_binary_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4611 - out_activation_loss: 0.4442 - concatenated_entropies_loss: 0.5288 - out_activation_binary_accuracy: 0.5000\n",
      "Mean Val Binary Accuracy: 63.62% (+/- 8.06%)\n",
      "Training subject 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4295 - out_activation_loss: 0.4118 - concatenated_entropies_loss: 0.5003 - out_activation_binary_accuracy: 0.5882\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4489 - out_activation_loss: 0.4022 - concatenated_entropies_loss: 0.6358 - out_activation_binary_accuracy: 0.5882\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4217 - out_activation_loss: 0.4095 - concatenated_entropies_loss: 0.4708 - out_activation_binary_accuracy: 0.5882\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3699 - out_activation_loss: 0.3201 - concatenated_entropies_loss: 0.5691 - out_activation_binary_accuracy: 0.6875\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3998 - out_activation_loss: 0.3593 - concatenated_entropies_loss: 0.5618 - out_activation_binary_accuracy: 0.6875\n",
      "Mean Val Binary Accuracy: 62.79% (+/- 4.86%)\n",
      "Training subject 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3664 - out_activation_loss: 0.3153 - concatenated_entropies_loss: 0.5707 - out_activation_binary_accuracy: 0.7000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3056 - out_activation_loss: 0.2260 - concatenated_entropies_loss: 0.6238 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3971 - out_activation_loss: 0.3577 - concatenated_entropies_loss: 0.5547 - out_activation_binary_accuracy: 0.6750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3772 - out_activation_loss: 0.3218 - concatenated_entropies_loss: 0.5988 - out_activation_binary_accuracy: 0.7000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3089 - out_activation_loss: 0.2569 - concatenated_entropies_loss: 0.5166 - out_activation_binary_accuracy: 0.7436\n",
      "Mean Val Binary Accuracy: 71.87% (+/- 3.58%)\n",
      "Training subject 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3231 - out_activation_loss: 0.2296 - concatenated_entropies_loss: 0.6971 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3218 - out_activation_loss: 0.2301 - concatenated_entropies_loss: 0.6887 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4577 - out_activation_loss: 0.4234 - concatenated_entropies_loss: 0.5952 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3455 - out_activation_loss: 0.2963 - concatenated_entropies_loss: 0.5423 - out_activation_binary_accuracy: 0.6750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3151 - out_activation_loss: 0.2242 - concatenated_entropies_loss: 0.6787 - out_activation_binary_accuracy: 0.8250\n",
      "Mean Val Binary Accuracy: 72.50% (+/- 8.94%)\n",
      "Training subject 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2142 - out_activation_loss: 0.1219 - concatenated_entropies_loss: 0.5834 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2233 - out_activation_loss: 0.1239 - concatenated_entropies_loss: 0.6207 - out_activation_binary_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2994 - out_activation_loss: 0.2085 - concatenated_entropies_loss: 0.6632 - out_activation_binary_accuracy: 0.7949\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2318 - out_activation_loss: 0.1569 - concatenated_entropies_loss: 0.5315 - out_activation_binary_accuracy: 0.8718\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2368 - out_activation_loss: 0.1211 - concatenated_entropies_loss: 0.6994 - out_activation_binary_accuracy: 0.8974\n",
      "Mean Val Binary Accuracy: 86.28% (+/- 3.86%)\n",
      "Training subject 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4330 - out_activation_loss: 0.3680 - concatenated_entropies_loss: 0.6928 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3397 - out_activation_loss: 0.2387 - concatenated_entropies_loss: 0.7436 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3587 - out_activation_loss: 0.2638 - concatenated_entropies_loss: 0.7384 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3313 - out_activation_loss: 0.2328 - concatenated_entropies_loss: 0.7253 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3804 - out_activation_loss: 0.2827 - concatenated_entropies_loss: 0.7711 - out_activation_binary_accuracy: 0.7179\n",
      "Mean Val Binary Accuracy: 74.86% (+/- 6.19%)\n",
      "Training subject 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3600 - out_activation_loss: 0.2799 - concatenated_entropies_loss: 0.6807 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3430 - out_activation_loss: 0.2530 - concatenated_entropies_loss: 0.7027 - out_activation_binary_accuracy: 0.7436\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3086 - out_activation_loss: 0.2275 - concatenated_entropies_loss: 0.6329 - out_activation_binary_accuracy: 0.8205\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3850 - out_activation_loss: 0.3205 - concatenated_entropies_loss: 0.6426 - out_activation_binary_accuracy: 0.7179\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3346 - out_activation_loss: 0.2582 - concatenated_entropies_loss: 0.6404 - out_activation_binary_accuracy: 0.7692\n",
      "Mean Val Binary Accuracy: 76.03% (+/- 3.43%)\n",
      "Training subject 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3122 - out_activation_loss: 0.2565 - concatenated_entropies_loss: 0.5353 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3204 - out_activation_loss: 0.2385 - concatenated_entropies_loss: 0.6478 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2985 - out_activation_loss: 0.2042 - concatenated_entropies_loss: 0.6757 - out_activation_binary_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3259 - out_activation_loss: 0.2213 - concatenated_entropies_loss: 0.7441 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3891 - out_activation_loss: 0.2902 - concatenated_entropies_loss: 0.7846 - out_activation_binary_accuracy: 0.7500\n",
      "Mean Val Binary Accuracy: 78.00% (+/- 3.67%)\n",
      "Training subject 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6007 - out_activation_loss: 0.6023 - concatenated_entropies_loss: 0.5942 - out_activation_binary_accuracy: 0.3514\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5539 - out_activation_loss: 0.5245 - concatenated_entropies_loss: 0.6716 - out_activation_binary_accuracy: 0.4324\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5007 - out_activation_loss: 0.4808 - concatenated_entropies_loss: 0.5802 - out_activation_binary_accuracy: 0.4595\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4143 - out_activation_loss: 0.3974 - concatenated_entropies_loss: 0.4819 - out_activation_binary_accuracy: 0.6757\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4690 - out_activation_loss: 0.4658 - concatenated_entropies_loss: 0.4815 - out_activation_binary_accuracy: 0.5946\n",
      "Mean Val Binary Accuracy: 50.27% (+/- 11.67%)\n",
      "Training subject 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4640 - out_activation_loss: 0.4059 - concatenated_entropies_loss: 0.6964 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5043 - out_activation_loss: 0.4458 - concatenated_entropies_loss: 0.7381 - out_activation_binary_accuracy: 0.5128\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4070 - out_activation_loss: 0.3252 - concatenated_entropies_loss: 0.7341 - out_activation_binary_accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3460 - out_activation_loss: 0.2721 - concatenated_entropies_loss: 0.6416 - out_activation_binary_accuracy: 0.7436\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4408 - out_activation_loss: 0.3759 - concatenated_entropies_loss: 0.7002 - out_activation_binary_accuracy: 0.6154\n",
      "Mean Val Binary Accuracy: 62.78% (+/- 8.21%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los sujetos y guardar los resultados\n",
    "for sbj in range(1, 29):\n",
    "    results_df = CV_giga(sbj, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10b3eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T20:07:11.096451Z",
     "iopub.status.busy": "2024-08-13T20:07:11.096144Z",
     "iopub.status.idle": "2024-08-13T20:31:08.365356Z",
     "shell.execute_reply": "2024-08-13T20:31:08.364518Z"
    },
    "papermill": {
     "duration": 1437.354628,
     "end_time": "2024-08-13T20:31:08.407664",
     "exception": false,
     "start_time": "2024-08-13T20:07:11.053036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subject 30\n",
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5568 - out_activation_loss: 0.5052 - concatenated_entropies_loss: 0.7631 - out_activation_binary_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5436 - out_activation_loss: 0.4859 - concatenated_entropies_loss: 0.7742 - out_activation_binary_accuracy: 0.4400\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4672 - out_activation_loss: 0.3812 - concatenated_entropies_loss: 0.8113 - out_activation_binary_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5432 - out_activation_loss: 0.4769 - concatenated_entropies_loss: 0.8082 - out_activation_binary_accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5970 - out_activation_loss: 0.5694 - concatenated_entropies_loss: 0.7075 - out_activation_binary_accuracy: 0.4167\n",
      "Mean Val Binary Accuracy: 52.47% (+/- 9.52%)\n",
      "Training subject 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3687 - out_activation_loss: 0.2805 - concatenated_entropies_loss: 0.7217 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3423 - out_activation_loss: 0.2362 - concatenated_entropies_loss: 0.7668 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3828 - out_activation_loss: 0.2795 - concatenated_entropies_loss: 0.7963 - out_activation_binary_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3716 - out_activation_loss: 0.2876 - concatenated_entropies_loss: 0.7078 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4324 - out_activation_loss: 0.3549 - concatenated_entropies_loss: 0.7427 - out_activation_binary_accuracy: 0.6154\n",
      "Mean Val Binary Accuracy: 72.81% (+/- 6.14%)\n",
      "Training subject 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4782 - out_activation_loss: 0.4052 - concatenated_entropies_loss: 0.7701 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5519 - out_activation_loss: 0.5048 - concatenated_entropies_loss: 0.7402 - out_activation_binary_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4624 - out_activation_loss: 0.3966 - concatenated_entropies_loss: 0.7257 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4602 - out_activation_loss: 0.3958 - concatenated_entropies_loss: 0.7181 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4849 - out_activation_loss: 0.4201 - concatenated_entropies_loss: 0.7443 - out_activation_binary_accuracy: 0.6000\n",
      "Mean Val Binary Accuracy: 57.00% (+/- 4.30%)\n",
      "Training subject 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3596 - out_activation_loss: 0.4328 - concatenated_entropies_loss: 0.0666 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4448 - out_activation_loss: 0.5205 - concatenated_entropies_loss: 0.1420 - out_activation_binary_accuracy: 0.5250\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5520 - out_activation_loss: 0.6356 - concatenated_entropies_loss: 0.2175 - out_activation_binary_accuracy: 0.4000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3895 - out_activation_loss: 0.4535 - concatenated_entropies_loss: 0.1337 - out_activation_binary_accuracy: 0.5250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4673 - out_activation_loss: 0.4682 - concatenated_entropies_loss: 0.4636 - out_activation_binary_accuracy: 0.5128\n",
      "Mean Val Binary Accuracy: 50.76% (+/- 5.79%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "for sbj in range(30, 34):\n",
    "    results_df = CV_giga(sbj, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a96ca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T20:31:08.501790Z",
     "iopub.status.busy": "2024-08-13T20:31:08.501468Z",
     "iopub.status.idle": "2024-08-13T22:26:07.087615Z",
     "shell.execute_reply": "2024-08-13T22:26:07.086543Z"
    },
    "papermill": {
     "duration": 6898.660007,
     "end_time": "2024-08-13T22:26:07.113730",
     "exception": false,
     "start_time": "2024-08-13T20:31:08.453723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subject 35\n",
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2850 - out_activation_loss: 0.1671 - concatenated_entropies_loss: 0.7565 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2814 - out_activation_loss: 0.1746 - concatenated_entropies_loss: 0.7087 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3026 - out_activation_loss: 0.1970 - concatenated_entropies_loss: 0.7250 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2595 - out_activation_loss: 0.1357 - concatenated_entropies_loss: 0.7545 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2975 - out_activation_loss: 0.1728 - concatenated_entropies_loss: 0.7962 - out_activation_binary_accuracy: 0.8250\n",
      "Mean Val Binary Accuracy: 84.00% (+/- 3.00%)\n",
      "Training subject 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4864 - out_activation_loss: 0.4132 - concatenated_entropies_loss: 0.7794 - out_activation_binary_accuracy: 0.6410\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3963 - out_activation_loss: 0.3140 - concatenated_entropies_loss: 0.7257 - out_activation_binary_accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4595 - out_activation_loss: 0.3998 - concatenated_entropies_loss: 0.6980 - out_activation_binary_accuracy: 0.5641\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3886 - out_activation_loss: 0.3023 - concatenated_entropies_loss: 0.7337 - out_activation_binary_accuracy: 0.7436\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3539 - out_activation_loss: 0.2658 - concatenated_entropies_loss: 0.7065 - out_activation_binary_accuracy: 0.8205\n",
      "Mean Val Binary Accuracy: 69.23% (+/- 8.73%)\n",
      "Training subject 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2965 - out_activation_loss: 0.2328 - concatenated_entropies_loss: 0.5511 - out_activation_binary_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3019 - out_activation_loss: 0.2593 - concatenated_entropies_loss: 0.4725 - out_activation_binary_accuracy: 0.7750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3570 - out_activation_loss: 0.2894 - concatenated_entropies_loss: 0.6276 - out_activation_binary_accuracy: 0.6750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3236 - out_activation_loss: 0.2695 - concatenated_entropies_loss: 0.5400 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3057 - out_activation_loss: 0.2324 - concatenated_entropies_loss: 0.5991 - out_activation_binary_accuracy: 0.7750\n",
      "Mean Val Binary Accuracy: 75.50% (+/- 4.30%)\n",
      "Training subject 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4033 - out_activation_loss: 0.3176 - concatenated_entropies_loss: 0.7458 - out_activation_binary_accuracy: 0.7179\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5031 - out_activation_loss: 0.4397 - concatenated_entropies_loss: 0.7565 - out_activation_binary_accuracy: 0.5789\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4782 - out_activation_loss: 0.4389 - concatenated_entropies_loss: 0.6355 - out_activation_binary_accuracy: 0.5526\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5511 - out_activation_loss: 0.5222 - concatenated_entropies_loss: 0.6665 - out_activation_binary_accuracy: 0.4737\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5140 - out_activation_loss: 0.4588 - concatenated_entropies_loss: 0.7348 - out_activation_binary_accuracy: 0.5263\n",
      "Mean Val Binary Accuracy: 56.99% (+/- 8.18%)\n",
      "Training subject 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4283 - out_activation_loss: 0.4127 - concatenated_entropies_loss: 0.4910 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4409 - out_activation_loss: 0.4088 - concatenated_entropies_loss: 0.5696 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4165 - out_activation_loss: 0.3980 - concatenated_entropies_loss: 0.4904 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4219 - out_activation_loss: 0.4057 - concatenated_entropies_loss: 0.4866 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4251 - out_activation_loss: 0.4102 - concatenated_entropies_loss: 0.4850 - out_activation_binary_accuracy: 0.5897\n",
      "Mean Val Binary Accuracy: 60.29% (+/- 2.98%)\n",
      "Training subject 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4547 - out_activation_loss: 0.4139 - concatenated_entropies_loss: 0.6181 - out_activation_binary_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4941 - out_activation_loss: 0.4729 - concatenated_entropies_loss: 0.5787 - out_activation_binary_accuracy: 0.5750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5384 - out_activation_loss: 0.5403 - concatenated_entropies_loss: 0.5311 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5146 - out_activation_loss: 0.4963 - concatenated_entropies_loss: 0.5880 - out_activation_binary_accuracy: 0.4500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4594 - out_activation_loss: 0.4229 - concatenated_entropies_loss: 0.6056 - out_activation_binary_accuracy: 0.5750\n",
      "Mean Val Binary Accuracy: 55.00% (+/- 5.24%)\n",
      "Training subject 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2124 - out_activation_loss: 0.1012 - concatenated_entropies_loss: 0.6573 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2596 - out_activation_loss: 0.1700 - concatenated_entropies_loss: 0.6182 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2047 - out_activation_loss: 0.1076 - concatenated_entropies_loss: 0.5932 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2103 - out_activation_loss: 0.1392 - concatenated_entropies_loss: 0.4949 - out_activation_binary_accuracy: 0.8500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1956 - out_activation_loss: 0.0877 - concatenated_entropies_loss: 0.6274 - out_activation_binary_accuracy: 0.9231\n",
      "Mean Val Binary Accuracy: 88.96% (+/- 2.50%)\n",
      "Training subject 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3795 - out_activation_loss: 0.2871 - concatenated_entropies_loss: 0.7495 - out_activation_binary_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4406 - out_activation_loss: 0.3747 - concatenated_entropies_loss: 0.7038 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5129 - out_activation_loss: 0.4488 - concatenated_entropies_loss: 0.7691 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4355 - out_activation_loss: 0.3663 - concatenated_entropies_loss: 0.7125 - out_activation_binary_accuracy: 0.7000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5055 - out_activation_loss: 0.4423 - concatenated_entropies_loss: 0.7583 - out_activation_binary_accuracy: 0.5750\n",
      "Mean Val Binary Accuracy: 63.50% (+/- 6.82%)\n",
      "Training subject 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0742 - out_activation_loss: 0.0127 - concatenated_entropies_loss: 0.3204 - out_activation_binary_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1513 - out_activation_loss: 0.0532 - concatenated_entropies_loss: 0.5438 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1282 - out_activation_loss: 0.0339 - concatenated_entropies_loss: 0.5057 - out_activation_binary_accuracy: 0.9750\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0925 - out_activation_loss: 0.0060 - concatenated_entropies_loss: 0.4384 - out_activation_binary_accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1330 - out_activation_loss: 0.0294 - concatenated_entropies_loss: 0.5475 - out_activation_binary_accuracy: 0.9750\n",
      "Mean Val Binary Accuracy: 97.50% (+/- 2.74%)\n",
      "Training subject 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3316 - out_activation_loss: 0.2222 - concatenated_entropies_loss: 0.7692 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2257 - out_activation_loss: 0.1134 - concatenated_entropies_loss: 0.6750 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2739 - out_activation_loss: 0.1747 - concatenated_entropies_loss: 0.6708 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2481 - out_activation_loss: 0.1701 - concatenated_entropies_loss: 0.5602 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2540 - out_activation_loss: 0.1422 - concatenated_entropies_loss: 0.7012 - out_activation_binary_accuracy: 0.9000\n",
      "Mean Val Binary Accuracy: 85.00% (+/- 3.16%)\n",
      "Training subject 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2868 - out_activation_loss: 0.1891 - concatenated_entropies_loss: 0.6777 - out_activation_binary_accuracy: 0.9000\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4524 - out_activation_loss: 0.3904 - concatenated_entropies_loss: 0.7004 - out_activation_binary_accuracy: 0.6250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3914 - out_activation_loss: 0.3113 - concatenated_entropies_loss: 0.7118 - out_activation_binary_accuracy: 0.7250\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4982 - out_activation_loss: 0.4616 - concatenated_entropies_loss: 0.6444 - out_activation_binary_accuracy: 0.5500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4178 - out_activation_loss: 0.3418 - concatenated_entropies_loss: 0.7218 - out_activation_binary_accuracy: 0.7000\n",
      "Mean Val Binary Accuracy: 70.00% (+/- 11.73%)\n",
      "Training subject 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3611 - out_activation_loss: 0.3111 - concatenated_entropies_loss: 0.5611 - out_activation_binary_accuracy: 0.7292\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3494 - out_activation_loss: 0.2943 - concatenated_entropies_loss: 0.5698 - out_activation_binary_accuracy: 0.7292\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3383 - out_activation_loss: 0.2748 - concatenated_entropies_loss: 0.5923 - out_activation_binary_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3462 - out_activation_loss: 0.2941 - concatenated_entropies_loss: 0.5547 - out_activation_binary_accuracy: 0.6875\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3145 - out_activation_loss: 0.2566 - concatenated_entropies_loss: 0.5463 - out_activation_binary_accuracy: 0.7660\n",
      "Mean Val Binary Accuracy: 73.24% (+/- 2.64%)\n",
      "Training subject 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4188 - out_activation_loss: 0.3570 - concatenated_entropies_loss: 0.6658 - out_activation_binary_accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3369 - out_activation_loss: 0.2606 - concatenated_entropies_loss: 0.6420 - out_activation_binary_accuracy: 0.7436\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4665 - out_activation_loss: 0.4108 - concatenated_entropies_loss: 0.6894 - out_activation_binary_accuracy: 0.5789\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3723 - out_activation_loss: 0.3068 - concatenated_entropies_loss: 0.6344 - out_activation_binary_accuracy: 0.7105\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3626 - out_activation_loss: 0.2718 - concatenated_entropies_loss: 0.7256 - out_activation_binary_accuracy: 0.7632\n",
      "Mean Val Binary Accuracy: 69.26% (+/- 6.56%)\n",
      "Training subject 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1382 - out_activation_loss: 0.0686 - concatenated_entropies_loss: 0.4164 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1431 - out_activation_loss: 0.0514 - concatenated_entropies_loss: 0.5095 - out_activation_binary_accuracy: 0.9750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2270 - out_activation_loss: 0.1728 - concatenated_entropies_loss: 0.4440 - out_activation_binary_accuracy: 0.8250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2189 - out_activation_loss: 0.1378 - concatenated_entropies_loss: 0.5435 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1052 - out_activation_loss: 0.0424 - concatenated_entropies_loss: 0.3562 - out_activation_binary_accuracy: 0.9744\n",
      "Mean Val Binary Accuracy: 91.49% (+/- 5.82%)\n",
      "Training subject 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3504 - out_activation_loss: 0.2594 - concatenated_entropies_loss: 0.7144 - out_activation_binary_accuracy: 0.7692\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2571 - out_activation_loss: 0.1334 - concatenated_entropies_loss: 0.7522 - out_activation_binary_accuracy: 0.9231\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3488 - out_activation_loss: 0.2506 - concatenated_entropies_loss: 0.7418 - out_activation_binary_accuracy: 0.7105\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2630 - out_activation_loss: 0.1413 - concatenated_entropies_loss: 0.7501 - out_activation_binary_accuracy: 0.8684\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3136 - out_activation_loss: 0.1951 - concatenated_entropies_loss: 0.7876 - out_activation_binary_accuracy: 0.7895\n",
      "Mean Val Binary Accuracy: 81.21% (+/- 7.50%)\n",
      "Training subject 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2692 - out_activation_loss: 0.1590 - concatenated_entropies_loss: 0.7103 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2141 - out_activation_loss: 0.0874 - concatenated_entropies_loss: 0.7209 - out_activation_binary_accuracy: 0.9750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2163 - out_activation_loss: 0.1013 - concatenated_entropies_loss: 0.6764 - out_activation_binary_accuracy: 0.9250\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2500 - out_activation_loss: 0.1370 - concatenated_entropies_loss: 0.7018 - out_activation_binary_accuracy: 0.8750\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2754 - out_activation_loss: 0.1784 - concatenated_entropies_loss: 0.6633 - out_activation_binary_accuracy: 0.8500\n",
      "Mean Val Binary Accuracy: 90.00% (+/- 4.47%)\n",
      "Training subject 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6345 - out_activation_loss: 0.6228 - concatenated_entropies_loss: 0.6810 - out_activation_binary_accuracy: 0.3333\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4941 - out_activation_loss: 0.4547 - concatenated_entropies_loss: 0.6520 - out_activation_binary_accuracy: 0.5641\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4944 - out_activation_loss: 0.4458 - concatenated_entropies_loss: 0.6887 - out_activation_binary_accuracy: 0.5128\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4973 - out_activation_loss: 0.4664 - concatenated_entropies_loss: 0.6212 - out_activation_binary_accuracy: 0.5641\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5967 - out_activation_loss: 0.5699 - concatenated_entropies_loss: 0.7039 - out_activation_binary_accuracy: 0.4474\n",
      "Mean Val Binary Accuracy: 48.43% (+/- 8.68%)\n",
      "Training subject 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 512.000000 to 128.000000 Hz.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4661 - out_activation_loss: 0.4019 - concatenated_entropies_loss: 0.7230 - out_activation_binary_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4257 - out_activation_loss: 0.3334 - concatenated_entropies_loss: 0.7949 - out_activation_binary_accuracy: 0.6750\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4702 - out_activation_loss: 0.3929 - concatenated_entropies_loss: 0.7795 - out_activation_binary_accuracy: 0.6500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5246 - out_activation_loss: 0.4612 - concatenated_entropies_loss: 0.7784 - out_activation_binary_accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5092 - out_activation_loss: 0.4556 - concatenated_entropies_loss: 0.7233 - out_activation_binary_accuracy: 0.5250\n",
      "Mean Val Binary Accuracy: 59.00% (+/- 6.82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/878219599.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "for sbj in range(35, 53):\n",
    "    results_df = CV_giga(sbj, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8ac5c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T22:26:07.245943Z",
     "iopub.status.busy": "2024-08-13T22:26:07.245079Z",
     "iopub.status.idle": "2024-08-13T22:26:07.501223Z",
     "shell.execute_reply": "2024-08-13T22:26:07.500350Z"
    },
    "papermill": {
     "duration": 0.323389,
     "end_time": "2024-08-13T22:26:07.503252",
     "exception": false,
     "start_time": "2024-08-13T22:26:07.179863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject  Mean Accuracy  Standard Deviation\n",
      "0       1.0       0.750000            0.080623\n",
      "1       2.0       0.565000            0.084558\n",
      "2       3.0       0.935000            0.040620\n",
      "3       4.0       0.875000            0.070711\n",
      "4       5.0       0.738590            0.044162\n",
      "5       6.0       0.769365            0.049226\n",
      "6       7.0       0.520833            0.054327\n",
      "7       8.0       0.535897            0.101280\n",
      "8       9.0       0.708333            0.018634\n",
      "9      10.0       0.805000            0.043012\n",
      "10     11.0       0.510000            0.093005\n",
      "11     12.0       0.673109            0.073869\n",
      "12     13.0       0.880000            0.036742\n",
      "13     14.0       0.960000            0.033912\n",
      "14     15.0       0.779892            0.028167\n",
      "15     16.0       0.608077            0.040089\n",
      "16     17.0       0.530000            0.043012\n",
      "17     18.0       0.605000            0.088600\n",
      "18     19.0       0.636207            0.080575\n",
      "19     20.0       0.627941            0.048630\n",
      "20     21.0       0.718718            0.035772\n",
      "21     22.0       0.725000            0.089443\n",
      "22     23.0       0.862821            0.038581\n",
      "23     24.0       0.748590            0.061875\n",
      "24     25.0       0.760256            0.034305\n",
      "25     26.0       0.780000            0.036742\n",
      "26     27.0       0.502703            0.116687\n",
      "27     28.0       0.627821            0.082135\n",
      "28     30.0       0.524667            0.095163\n",
      "29     31.0       0.728077            0.061389\n",
      "30     32.0       0.570000            0.043012\n",
      "31     33.0       0.507564            0.057885\n",
      "32     35.0       0.840000            0.030000\n",
      "33     36.0       0.692308            0.087330\n",
      "34     37.0       0.755000            0.043012\n",
      "35     38.0       0.569906            0.081799\n",
      "36     39.0       0.602949            0.029788\n",
      "37     40.0       0.550000            0.052440\n",
      "38     41.0       0.889615            0.024973\n",
      "39     42.0       0.635000            0.068191\n",
      "40     43.0       0.975000            0.027386\n",
      "41     44.0       0.850000            0.031623\n",
      "42     45.0       0.700000            0.117260\n",
      "43     46.0       0.732358            0.026354\n",
      "44     47.0       0.692578            0.065558\n",
      "45     48.0       0.914872            0.058178\n",
      "46     49.0       0.812146            0.075040\n",
      "47     50.0       0.900000            0.044721\n",
      "48     51.0       0.484345            0.086839\n",
      "49     52.0       0.590000            0.068191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='cross_validation_results_gmrrnet.xlsx' target='_blank'>cross_validation_results_gmrrnet.xlsx</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/cross_validation_results_gmrrnet.xlsx"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar los resultados en un archivo xlsx\n",
    "results_df.to_excel('cross_validation_results_gmrrnet.xlsx', index=False)\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(results_df)\n",
    "\n",
    "# Generar un enlace de descarga para el archivo xlsx\n",
    "FileLink('cross_validation_results_gmrrnet.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3008205,
     "sourceId": 5175158,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18828.005277,
   "end_time": "2024-08-13T22:26:11.128491",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T17:12:23.123214",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
