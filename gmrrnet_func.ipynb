{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **GMRRNet funcions:** \n\nEste cuaderno documenta todas las funciones y clases utilizadas para el correcto y buen funcionamiento del modelo.","metadata":{}},{"cell_type":"markdown","source":"# **Instalamos lo necesario e importamos librerÃ­as**","metadata":{}},{"cell_type":"code","source":"!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-08-14T16:10:50.543949Z","iopub.execute_input":"2024-08-14T16:10:50.544265Z","iopub.status.idle":"2024-08-14T16:11:59.888622Z","shell.execute_reply.started":"2024-08-14T16:10:50.544236Z","shell.execute_reply":"2024-08-14T16:11:59.887362Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/UN-GCPDS/python-gcpds.databases\n  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-3tsee6eh\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-3tsee6eh\n  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit c35637e1a19d7cd21656496339c1dedae6714916\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.7.5)\nRequirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.7.1)\nRequirement already satisfied: tables in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (4.66.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (2.2.2)\nCollecting gdown (from gcpds-databases==0.2)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (2.32.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (3.1.2)\nRequirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (0.3)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (1.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.4)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.10.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (9.0.0)\nRequirement already satisfied: blosc2>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.7.0)\nRequirement already satisfied: ndindex>=1.4 in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.8)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.0.7)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->gcpds-databases==0.2) (3.11.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne->gcpds-databases==0.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: gcpds-databases\n  Building wheel for gcpds-databases (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=94504 sha256=c97b03346d976a26fc2c7ef2eb8975c507bfdc361b9bfd0eb954fb2359bc873e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k5ly5454/wheels/8e/66/a7/91b78b1787a3e4d17cb82ea2da67845aa9389012c0ed8280b0\nSuccessfully built gcpds-databases\nInstalling collected packages: gdown, gcpds-databases\nSuccessfully installed gcpds-databases-0.2 gdown-5.2.0\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models\n  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to /tmp/pip-req-build-zsx2f4i0\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models /tmp/pip-req-build-zsx2f4i0\n  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to commit 975885b1f6814fd5958199919b33e02a6a9aa152\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\n  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\nCollecting moabb (from EEG_Tensorflow_models==0.2)\n  Downloading moabb-1.1.0-py3-none-any.whl.metadata (16 kB)\nCollecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow>=2.8 in /opt/conda/lib/python3.10/site-packages (from EEG_Tensorflow_models==0.2) (2.15.0)\nCollecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.7.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.10.0)\nCollecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading skorch-1.0.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=2.8->EEG_Tensorflow_models==0.2)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: PyYAML<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.1)\nCollecting coverage<8.0.0,>=7.0.1 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\nCollecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading edfio-0.4.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.61.0)\nCollecting mne-bids<0.15,>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading mne_bids-0.14-py2.py3-none-any.whl.metadata (4.8 kB)\nCollecting pandas (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\nCollecting pyriemann<0.7,>=0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pyriemann-0.6-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting pytest<8.0.0,>=7.4.0 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (2.32.3)\nCollecting scikit-learn>=1.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (4.66.4)\nRequirement already satisfied: urllib3<2.0.0,>=1.26.15 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.26.18)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (9.5.0)\nRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.14)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.33.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.42.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (5.9.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.2)\nRequirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2023.3.post1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (3.11.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyriemann<0.7,>=0.6->moabb->EEG_Tensorflow_models==0.2) (1.4.2)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (2024.7.4)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->moabb->EEG_Tensorflow_models==0.2) (3.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.3)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.2.2)\nDownloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading moabb-1.1.0-py3-none-any.whl (230 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m230.7/230.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m234.7/234.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading edfio-0.4.3-py3-none-any.whl (25 kB)\nDownloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mne_bids-0.14-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyriemann-0.6-py2.py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest-7.4.4-py3-none-any.whl (325 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading skorch-1.0.0-py3-none-any.whl (239 kB)\n\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\n  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29376 sha256=f551115b8d56f90d820c9adb4b98385c67d73f4152ac5c5c9750945b29337e5c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-l499e0a1/wheels/05/dc/8a/9d552a33fb901c0d7ab2a72746b5ea17643c570811c711d568\nSuccessfully built EEG_Tensorflow_models\nInstalling collected packages: typeguard, keras, edflib-python, edfio, coverage, tf-keras-vis, tensorflow-addons, scikit-learn, pytest, pandas, skorch, pyriemann, mne-bids, braindecode, moabb, EEG_Tensorflow_models\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.1.5\n    Uninstalling typeguard-4.1.5:\n      Successfully uninstalled typeguard-4.1.5\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pytest\n    Found existing installation: pytest 8.2.2\n    Uninstalling pytest-8.2.2:\n      Successfully uninstalled pytest-8.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.2\n    Uninstalling pandas-2.2.2:\n      Successfully uninstalled pandas-2.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ncudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-cudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.7 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2024.6.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nxarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 coverage-7.6.1 edfio-0.4.3 edflib-python-1.0.8 keras-2.15.0 mne-bids-0.14 moabb-1.1.0 pandas-1.5.3 pyriemann-0.6 pytest-7.4.4 scikit-learn-1.5.1 skorch-1.0.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from gcpds.databases import GIGA_MI_ME\nfrom typing import Optional, Sequence, Tuple\nimport matplotlib.pyplot as plt\nimport mne\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import  Input, Flatten, Dense, Activation, Dropout, concatenate, Layer, Conv2D, AveragePooling2D, SeparableConv2D, DepthwiseConv2D, BatchNormalization, SpatialDropout2D, Lambda\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.losses import Loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom keras_tuner import HyperModel, RandomSearch, Objective\nfrom IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:11:59.890598Z","iopub.execute_input":"2024-08-14T16:11:59.890899Z","iopub.status.idle":"2024-08-14T16:12:16.068053Z","shell.execute_reply.started":"2024-08-14T16:11:59.890870Z","shell.execute_reply":"2024-08-14T16:12:16.067272Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-14 16:12:05.400485: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-14 16:12:05.400593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-14 16:12:05.562731: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **FunciÃ³n que carga la base de datos GIGA**\n\nRecuerde que es importante importar esta base de datos que se encuentra como \"giga-science-dataset\"","metadata":{}},{"cell_type":"code","source":"def load_GIGA(db: GIGA_MI_ME,\n              sbj: int,\n              eeg_ch_names: Sequence[str],\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    This function loads the GIGA-Science dataset locally.\n    \n    Parameters\n    ----------\n    db: GIGA_MI_ME\n        A GIGA_MI_ME object created by the gcpds.databases.GIGA_MI_ME module\n    sbj: int\n        The subject to load\n    eeg_ch_names: Sequence[str]\n        The EEG channel names in order\n    fs: float\n        The sampling frecuency\n    f_bank: np.ndarray\n        The frecuency range(s) to use\n    vwt: np.ndarray\n        The time window to load\n    new_fs: float\n        The new sampling frecuency to resample the data to\n    \n    Returns\n    ----------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing the EEG signals for each trial and the corresponding label\n    \n    Notes\n    ----------\n    The database description can be found here:\n    https://academic.oup.com/gigascience/article/6/7/gix034/3796323\n    \"\"\"\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    #print(np.mean (X), np.var(X))\n    return X, y\n\ndef butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n    \"\"\"\n    Apply digital butterworth filter\n    INPUT\n    ------\n    1. X: (D array)\n    array with signals.\n    2. N: (int+)\n    The order of the filter.\n    3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the â-3 dB pointâ).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n    4. btype: (str) {âlowpassâ, âhighpassâ, âbandpassâ, âbandstopâ}\n    The type of filter\n    5. fs: (float+)\n    The sampling frequency of the digital system.\n    6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n    7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is âoddâ.\n    8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n    9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either âpadâ or âgustâ. When method is âpadâ, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is âgustâ, Gustafssonâs method is used, and padtype and padlen are ignored.\n    10. irlen: (int) or None, Default=nONE\n    When method is âgustâ, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n    OUTPUT\n    ------\n    X_fil: (D array)\n    array with filtered signals.\n    \"\"\"\n    b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n    return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Time frequency representation of EEG signals.\n\n    Parameters\n    ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n    Methods\n    -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n    \"\"\"\n    def __init__(self, sfreq, f_bank=None, vwt=None):\n        self.sfreq = sfreq\n        self.f_bank = f_bank\n        self.vwt = vwt\n    # ------------------------------------------------------------------------------\n\n    def _validation_param(self):\n        \"\"\"\n        Validate Time-Frequency characterization parameters.\n        INPUT\n        -----\n          1. self\n        ------\n          2. None\n        \"\"\"\n        if self.sfreq <= 0:\n            raise ValueError('Non negative sampling frequency is accepted')\n\n\n        if self.f_bank is None:\n            self.flag_f_bank = False\n        elif self.f_bank.ndim != 2:\n            raise ValueError('Band frequencies have to be a 2D array')\n        else:\n            self.flag_f_bank = True\n\n        if self.vwt is None:\n            self.flag_vwt = False\n        elif self.vwt.ndim != 2:\n            raise ValueError('Time windows have to be a 2D array')\n        else:\n            self.flag_vwt = True\n\n    # ------------------------------------------------------------------------------\n    def _filter_bank(self, X):\n        \"\"\"\n        Filter bank Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n        \"\"\"\n        X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n        for f in np.arange(self.f_bank.shape[0]):\n            X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n        return X_f\n\n    # ------------------------------------------------------------------------------\n    def _sliding_windows(self, X):\n        \"\"\"\n        Sliding Windows Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n        \"\"\"\n        window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n        X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n        for w in np.arange(self.vwt.shape[0]):\n            X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n        return X_w\n\n    # ------------------------------------------------------------------------------\n    def fit(self, X, y=None):\n        \"\"\"\n        fit.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n          2. y: (1D array) target labels. Default=None\n        OUTPUT\n        ------\n          1. None\n        \"\"\"\n        pass\n\n    # ------------------------------------------------------------------------------\n    def transform(self, X, y=None):\n        \"\"\"\n        Time frequency representation of EEG signals.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n        OUTPUT\n        ------\n          1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n        \"\"\"\n        self._validation_param()     #Validate sfreq, f_freq, vwt\n\n        #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n        if self.flag_f_bank:\n            X_f = self._filter_bank(X)\n        else:\n            X_f = X[:,:,:,np.newaxis]\n\n        if self.flag_vwt:\n            X_wf = []\n            for f in range(X_f.shape[3]):\n                X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n            X_wf = np.stack(X_wf, axis=-1)\n        else:\n            X_wf = X_f[:,:,:,np.newaxis,:]\n        return X_wf\n    \ndef plot_training_history(history):\n    # Extraer datos de history\n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    train_out_activation_loss = history.history['out_activation_loss']\n    val_out_activation_loss = history.history['val_out_activation_loss']\n    train_concatenate_2_loss = history.history['concatenated_entropies_loss']\n    val_concatenate_2_loss = history.history['val_concatenated_entropies_loss']\n    train_out_activation_acc = history.history['out_activation_binary_accuracy']\n    val_out_activation_acc = history.history['val_out_activation_binary_accuracy']\n    epochs = range(1, len(train_loss) + 1)  # NÃºmero de Ã©pocas\n\n    # Graficar pÃ©rdida\n    plt.figure(figsize=(8, 4))\n    plt.plot(epochs, train_loss, 'b', label='Training total loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation total loss')\n    plt.plot(epochs, train_out_activation_loss, 'g', label='Training out_activation_loss')\n    plt.plot(epochs, val_out_activation_loss, 'm', label='Validation out_activation_loss')\n    plt.plot(epochs, train_concatenate_2_loss, 'y', label='Training concatenated_entropies_loss')\n    plt.plot(epochs, val_concatenate_2_loss, 'c', label='Validation concatenated_entropies_loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n    # Graficar precisiÃ³n\n    plt.figure(figsize=(8, 4))\n    plt.plot(epochs, train_out_activation_acc, 'b', label='Training out_activation_binary_accuracy')\n    plt.plot(epochs, val_out_activation_acc, 'r', label='Validation out_activation_binary_accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.073289Z","iopub.execute_input":"2024-08-14T16:12:16.073648Z","iopub.status.idle":"2024-08-14T16:12:16.108290Z","shell.execute_reply.started":"2024-08-14T16:12:16.073623Z","shell.execute_reply":"2024-08-14T16:12:16.107373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Gaussian Kernel Layer**\n\nEsta es una capa custom de keras para poder aplicar el kernel gaussiano en la red.\n","metadata":{}},{"cell_type":"code","source":"class GaussianKernelLayer(Layer):\n    \"\"\"\n    Capa personalizada de Keras que aplica un kernel Gaussiano sobre las entradas.\n\n    Esta capa calcula la distancia euclidiana al cuadrado entre pares de puntos y luego aplica una funciÃ³n kernel Gaussiana \n    para transformar esas distancias en similitudes, lo que es Ãºtil en el procesamiento de seÃ±ales como EEG o en la construcciÃ³n \n    de redes neuronales con funciones de kernel.\n\n    ParÃ¡metros:\n    -----------\n    sigma : float, opcional (por defecto=1.0)\n        DesviaciÃ³n estÃ¡ndar de la funciÃ³n kernel Gaussiana. Controla el alcance o \"spread\" de la Gaussiana.\n\n    MÃ©todos:\n    --------\n    build(input_shape):\n        MÃ©todo de construcciÃ³n que inicializa los componentes internos de la capa basados en la forma de la entrada.\n    \n    call(inputs):\n        MÃ©todo que aplica la transformaciÃ³n de la capa a las entradas.\n        \n        ParÃ¡metros:\n        -----------\n        inputs : Tensor\n            Tensor de entrada con la forma `(N, C, T, F)` donde:\n            - N: NÃºmero de muestras en el lote.\n            - C: NÃºmero de canales o caracterÃ­sticas.\n            - T: NÃºmero de pasos temporales.\n            - F: NÃºmero de filtros.\n\n        Retorna:\n        --------\n        gaussian_kernel : Tensor\n            Tensor con la misma forma que el tensor de entrada, pero donde cada entrada ha sido transformada por el kernel Gaussiano.\n    \"\"\"\n\n    def __init__(self, sigma=1.0, **kwargs):\n        super(GaussianKernelLayer, self).__init__(**kwargs)\n        self.sigma = sigma\n\n    def build(self, input_shape):\n        \"\"\"\n        Inicializa la capa. Este mÃ©todo es llamado una sola vez y se utiliza para construir las variables de la capa.\n\n        ParÃ¡metros:\n        -----------\n        input_shape : tuple\n            Forma de la entrada esperada por la capa.\n        \"\"\"\n        super(GaussianKernelLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        \"\"\"\n        Aplica la transformaciÃ³n del kernel Gaussiano a los datos de entrada.\n\n        ParÃ¡metros:\n        -----------\n        inputs : Tensor\n            Tensor de entrada de forma `(N, C, T, F)`.\n\n        Retorna:\n        --------\n        gaussian_kernel : Tensor\n            Tensor de salida donde se ha aplicado el kernel Gaussiano, con forma `(N, C, C, F)`.\n        \"\"\"\n        # DescomposiciÃ³n de la forma del tensor de entrada\n        N, C, T, F = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n        \n        # Reorganizar el tensor de entrada a la forma (N*F, C, T)\n        inputs = tf.transpose(inputs, perm=(0, 3, 1, 2))  # Cambia la forma a (N, F, C, T)\n        inputs_reshaped = tf.reshape(inputs, (N * F, C, T))\n        \n        # Calcular la distancia euclidiana al cuadrado entre pares de puntos\n        squared_differences = tf.expand_dims(inputs_reshaped, axis=2) - tf.expand_dims(inputs_reshaped, axis=1)  # (N*F, C, C, T)\n        squared_differences = tf.square(squared_differences)  # (N*F, C, C, T)\n        pairwise_distances_squared = tf.reduce_sum(squared_differences, axis=-1)  # (N*F, C, C)\n        pairwise_distances_squared = tf.reshape(pairwise_distances_squared, (N, F, C, C))  # (N, F, C, C)\n        pairwise_distances_squared = tf.transpose(pairwise_distances_squared, perm=(0, 2, 3, 1))  # (N, C, C, F)\n        \n        # Calcular el kernel Gaussiano\n        gaussian_kernel = tf.exp(-pairwise_distances_squared / (2.0 * tf.square(self.sigma)))\n        \n        return gaussian_kernel\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.128453Z","iopub.execute_input":"2024-08-14T16:12:16.128831Z","iopub.status.idle":"2024-08-14T16:12:16.145020Z","shell.execute_reply.started":"2024-08-14T16:12:16.128798Z","shell.execute_reply":"2024-08-14T16:12:16.144154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Inception Block**\n\nEs el bloque donde se aplican 3 kernels gaussianos y cada uno seguido de una capa convolucional con un nÃºmero especÃ­fico de filtros.","metadata":{}},{"cell_type":"code","source":"def inception_block(x, filters, sigmas):\n    \"\"\"\n    Construye un bloque de Inception personalizado que incluye capas de convoluciÃ³n y capas de kernel Gaussiano.\n\n    Este bloque Inception crea tres ramas, cada una aplicando un kernel Gaussiano seguido de una capa de convoluciÃ³n 2D. \n    Finalmente, las salidas de estas ramas se concatenan a lo largo del eje de los canales.\n\n    ParÃ¡metros:\n    -----------\n    x : Tensor\n        Tensor de entrada con forma `(N, C, T, F)` donde:\n        - N: NÃºmero de muestras en el lote.\n        - C: NÃºmero de canales o caracterÃ­sticas.\n        - T: NÃºmero de pasos temporales.\n        - F: NÃºmero de filtros o caracterÃ­sticas adicionales.\n\n    filters : list of int\n        Lista que contiene el nÃºmero de filtros para cada rama del bloque Inception. Debe ser una lista de tres enteros `[f1, f2, f3]` \n        donde `f1`, `f2`, y `f3` son el nÃºmero de filtros para las ramas 1, 2 y 3 respectivamente.\n\n    sigmas : list of float\n        Lista que contiene los valores de `sigma` para cada capa `GaussianKernelLayer` en las ramas del bloque Inception. Debe ser una lista \n        de tres valores `[sigma1, sigma2, sigma3]` donde `sigma1`, `sigma2`, y `sigma3` corresponden a las ramas 1, 2 y 3 respectivamente.\n\n    Retorna:\n    --------\n    branch_k1, branch_k2, branch_k3 : Tensors\n        Las salidas de las capas `GaussianKernelLayer` en las tres ramas, con forma `(N, C, C, F)`.\n\n    output : Tensor\n        La salida concatenada de las tres ramas despuÃ©s de la capa de convoluciÃ³n, con forma `(N, C, T, f1 + f2 + f3)`.\n\n    DescripciÃ³n:\n    ------------\n    Este bloque Inception se compone de las siguientes partes:\n    1. **Rama 1**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[0]` sobre la entrada `x`.\n        - Aplica una capa de convoluciÃ³n 2D con `f1` filtros de tamaÃ±o `(3, 3)` y activaciÃ³n `ReLU`.\n\n    2. **Rama 2**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[1]` sobre la entrada `x`.\n        - Aplica una capa de convoluciÃ³n 2D con `f2` filtros de tamaÃ±o `(3, 3)` y activaciÃ³n `ReLU`.\n\n    3. **Rama 3**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[2]` sobre la entrada `x`.\n        - Aplica una capa de convoluciÃ³n 2D con `f3` filtros de tamaÃ±o `(3, 3)` y activaciÃ³n `ReLU`.\n\n    Finalmente, las salidas de las tres ramas se concatenan a lo largo del eje de los canales.\n    \"\"\"\n\n    # Filtros\n    f1, f2, f3 = filters\n\n    # Rama 1: Aplicar el kernel Gaussiano seguido de una convoluciÃ³n 2D\n    branch_k1 = GaussianKernelLayer(sigma=sigmas[0], name=\"gaussian_layer_1\")(x)\n    branch1 = Conv2D(f1, (3, 3), padding='same', activation='relu')(branch_k1)\n\n    # Rama 2: Aplicar el kernel Gaussiano seguido de una convoluciÃ³n 2D\n    branch_k2 = GaussianKernelLayer(sigma=sigmas[1], name=\"gaussian_layer_2\")(x)\n    branch2 = Conv2D(f2, (3, 3), padding='same', activation='relu')(branch_k2)\n\n    # Rama 3: Aplicar el kernel Gaussiano seguido de una convoluciÃ³n 2D\n    branch_k3 = GaussianKernelLayer(sigma=sigmas[2], name=\"gaussian_layer_3\")(x)\n    branch3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(branch_k3)\n\n    # Concatenar las salidas de las tres ramas a lo largo del eje de los canales\n    output = concatenate([branch1, branch2, branch3], axis=-1)\n\n    return branch_k1, branch_k2, branch_k3, output\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.146333Z","iopub.execute_input":"2024-08-14T16:12:16.146894Z","iopub.status.idle":"2024-08-14T16:12:16.162003Z","shell.execute_reply.started":"2024-08-14T16:12:16.146869Z","shell.execute_reply":"2024-08-14T16:12:16.161094Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **InformaciÃ³n mutua - regularizador**\n\nPara calcular la informaciÃ³n mutua, necesitamos de la entropia de Renyi y la entropÃ­a de Renyi conjunta. De modo que usamos esta para hacer que las salidas de los kernels compartan \"la menor informaciÃ³n posible\" con el objetivo de calcular caracterÃ­sticas diferentes.","metadata":{}},{"cell_type":"code","source":"class RenyiMutualInformation(Loss):\n    def __init__(self, C, **kwargs):\n        self.C = C\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        y_true: \n        y_pred: N x (F+1) las F entropÃ­as marginales y la entropÃ­a conjunta\n        \"\"\"\n        \n        F = y_pred.shape[1]-1\n        entropy,  joint_entropy = tf.split(y_pred, [F,1], axis=-1)\n        \n        #Cast todo\n        entropy = tf.cast(entropy, tf.float64)\n        joint_entropy = tf.cast(joint_entropy, tf.float64)\n        log_C = tf.math.log(tf.cast(self.C, tf.float64))\n        \n        mutual_information = tf.math.abs((tf.expand_dims(tf.reduce_sum(entropy, axis=-1), axis=-1) - joint_entropy)) / (F * log_C) # normalizado\n\n\n        return mutual_information","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.163091Z","iopub.execute_input":"2024-08-14T16:12:16.163339Z","iopub.status.idle":"2024-08-14T16:12:16.177336Z","shell.execute_reply.started":"2024-08-14T16:12:16.163311Z","shell.execute_reply":"2024-08-14T16:12:16.176529Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **Renyi Entropy**\n\nEsta funciÃ³n recibe un tensor y calcula la entropÃ­a de Renyi para esta teniendo en cuenta la siguiente fÃ³rmula:\n\n\\begin{equation}\\label{eq:renyiEntropy}\n    S_\\alpha(\\tilde{\\mathbf{K}})=\\frac{1}{1-\\alpha}\\log\\left(\\tilde{\\mathbf{K}}^\\alpha\\right),\n\\end{equation}\ndonde $\\alpha>0$, $\\alpha\\neq1$, $\\tilde{\\mathbf{K}}\\in \\mathbb{R}^{C \\times C}$ tiene los elementos del kernel gaussiano, y $\\text{tr}(\\tilde{\\mathbf{K}})=1.$\n\nSe debe normalizar este, por ende se divide por el producto de los elementos diagonales de sus matrices cuadradas","metadata":{}},{"cell_type":"code","source":"def renyi_entropy(K, alpha=2):\n    \"\"\"\n    Calcula la entropÃ­a de RÃ©nyi para un tensor de entrada.\n\n    ParÃ¡metros:\n    -----------\n    K : Tensor\n        Un tensor de entrada de forma `(N, F, C, C)`, donde:\n        - N: NÃºmero de muestras en el lote.\n        - F: NÃºmero de filtros o caracterÃ­sticas.\n        - C: NÃºmero de canales o dimensiones de las matrices cuadradas dentro del tensor.\n\n    alpha : float, opcional\n        El parÃ¡metro de entropÃ­a de RÃ©nyi. Por defecto es 2.0.\n        - Cuando `alpha=2`, se aplica una optimizaciÃ³n especÃ­fica para este valor.\n\n    Retorna:\n    --------\n    Tensor\n        Un tensor de salida de forma `(N, F)`, que contiene la entropÃ­a de RÃ©nyi calculada para cada muestra y filtro.\n\n    DescripciÃ³n:\n    ------------\n    La entropÃ­a de RÃ©nyi es una generalizaciÃ³n de la entropÃ­a de Shannon, que depende de un parÃ¡metro `alpha`. Esta funciÃ³n \n    calcula la entropÃ­a de RÃ©nyi para cada una de las matrices cuadradas en el tensor `K` normalizado.\n\n    Pasos:\n    ------\n    1. **NormalizaciÃ³n del Kernel**:\n        - Se normaliza el tensor `K` dividiÃ©ndolo por el producto de los elementos diagonales de sus matrices cuadradas.\n        - Esta normalizaciÃ³n se realiza para estabilizar el cÃ¡lculo de la entropÃ­a.\n\n    2. **CÃ¡lculo de la EntropÃ­a**:\n        - Si `alpha=2`, se utiliza una optimizaciÃ³n que calcula la traza del producto matricial de `X` consigo mismo.\n        - Para otros valores de `alpha`, se calculan los autovalores de `X` y se utiliza la fÃ³rmula general para la entropÃ­a de RÃ©nyi.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    # Crear un tensor de ejemplo con la forma (N, F, C, C)\n    K = tf.random.normal((32, 10, 64, 64))\n\n    # Calcular la entropÃ­a de RÃ©nyi con alpha = 2\n    entropy = renyi_entropy(K, alpha=2)\n    print(entropy.shape)  # Salida: (32, 10)\n    ```\n\n    Notas:\n    ------\n    - La entropÃ­a de RÃ©nyi con `alpha=2` es especialmente Ãºtil en contextos donde se desea penalizar grandes concentraciones de probabilidad,\n      debido a que esta mÃ©trica es mÃ¡s sensible a distribuciones con pocos eventos de alta probabilidad.\n    - La funciÃ³n retorna la entropÃ­a negativa, lo que es estÃ¡ndar en la teorÃ­a de la informaciÃ³n, ya que una mayor concentraciÃ³n \n      de probabilidad corresponde a una menor entropÃ­a.\n    \"\"\"\n\n    # Obtener el nÃºmero de canales\n    C = K.shape[-1]\n\n    # Normalizamos el kernel antes de calcular la entropÃ­a\n\n    # Crear una mÃ¡scara para obtener los elementos diagonales\n    diag = tf.expand_dims(tf.linalg.diag_part(K), -1)\n    # Calcular el producto de los elementos diagonales\n    denominator = tf.math.sqrt(tf.linalg.matmul(diag, diag, transpose_b=True))\n    # NormalizaciÃ³n\n\n    X = (1/C) * tf.math.divide(K, denominator)\n    if alpha == 2:\n        # Realiza el producto matricial entre las dos Ãºltimas dimensiones\n        X_matmul = tf.linalg.matmul(X, X)\n        return -tf.math.log(tf.linalg.trace(X_matmul))\n    else:\n        # Calcula los autovalores y autovectores de las dos Ãºltimas dimensiones\n        e, _ = tf.linalg.eigh(X)\n        # Calcula la entropÃ­a de Renyi\n        return (tf.math.log(tf.reduce_sum(tf.math.real(tf.math.pow(e, alpha)), axis=-1)) / (1 - alpha))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.178627Z","iopub.execute_input":"2024-08-14T16:12:16.178898Z","iopub.status.idle":"2024-08-14T16:12:16.194906Z","shell.execute_reply.started":"2024-08-14T16:12:16.178875Z","shell.execute_reply":"2024-08-14T16:12:16.194022Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **Joint Renyi Entropy**\n\nCalculamos la entropÃ­a de $\\alpha$-Renyi conjunta de la siguiente manera:\n\n\\begin{equation}\\label{eq:jointREntropy}\n    S_\\alpha(\\tilde{\\mathbf{K}}_g, \\tilde{\\mathbf{K}}_{g'})=S_\\alpha\\left(\\frac{\\tilde{\\mathbf{K}}_g\\circ \\tilde{\\mathbf{K}}_{g'}}{\\text{tr}(\\tilde{\\mathbf{K}}_g\\circ \\tilde{\\mathbf{K}}_{g'})}\\right).\n\\end{equation} \n$\\circ$ es el producto de Hadamard.","metadata":{}},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"def joint_renyi_entropy(K, alpha):\n    \"\"\"\n    Calcula la entropÃ­a conjunta de RÃ©nyi para un tensor de entrada.\n\n    ParÃ¡metros:\n    -----------\n    K : Tensor\n        Un tensor de entrada de forma `(N, F, C, C)`, donde:\n        - N: NÃºmero de muestras en el lote.\n        - F: NÃºmero de filtros o caracterÃ­sticas.\n        - C: NÃºmero de canales o dimensiones de las matrices cuadradas dentro del tensor.\n\n    alpha : float\n        El parÃ¡metro de entropÃ­a de RÃ©nyi. Controla la sensibilidad de la mÃ©trica a diferentes distribuciones de probabilidad.\n\n    Retorna:\n    --------\n    Tensor\n        Un tensor de salida de forma `(N, 1)`, que contiene la entropÃ­a conjunta de RÃ©nyi calculada para cada muestra.\n\n    DescripciÃ³n:\n    ------------\n    Esta funciÃ³n calcula la entropÃ­a conjunta de RÃ©nyi, la cual mide la cantidad de incertidumbre en un sistema considerando mÃºltiples variables conjuntamente. La entropÃ­a conjunta es Ãºtil para evaluar la dependencia o interrelaciÃ³n entre variables.\n\n    Pasos:\n    ------\n    1. **Producto de los TÃ©rminos del Tensor**:\n        - Se realiza un producto a lo largo de la dimensiÃ³n `F` del tensor `K`, reduciendo asÃ­ el tensor de `(N, F, C, C)` a `(N, C, C)`.\n\n    2. **CÃ¡lculo de la Traza**:\n        - Se calcula la traza del tensor resultante, que es la suma de los elementos en la diagonal principal de las matrices cuadradas en `(N, C, C)`.\n        - La traza se expande y se repite para hacerla compatible con la dimensionalidad del tensor `K`.\n\n    3. **NormalizaciÃ³n**:\n        - Se normaliza el producto obtenido en el primer paso dividiÃ©ndolo por la traza expandida, lo que estabiliza el cÃ¡lculo de la entropÃ­a.\n\n    4. **CÃ¡lculo de la EntropÃ­a Conjunta**:\n        - Se pasa el tensor normalizado a la funciÃ³n `renyi_entropy`, que calcula la entropÃ­a de RÃ©nyi considerando la interrelaciÃ³n entre las variables.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    # Crear un tensor de ejemplo con la forma (N, F, C, C)\n    K = tf.random.normal((32, 10, 64, 64))\n\n    # Calcular la entropÃ­a conjunta de RÃ©nyi con alpha = 2\n    joint_entropy = joint_renyi_entropy(K, alpha=2)\n    print(joint_entropy.shape)  # Salida: (32, 1)\n    ```\n\n    Notas:\n    ------\n    - La entropÃ­a conjunta de RÃ©nyi es particularmente Ãºtil cuando se quiere evaluar la cantidad de informaciÃ³n compartida entre mÃºltiples variables.\n    - Al utilizar diferentes valores de `alpha`, se puede ajustar la sensibilidad de la mÃ©trica para enfatizar distribuciones de probabilidad mÃ¡s concentradas o mÃ¡s dispersas.\n    \"\"\"\n\n    # Obtener el nÃºmero de canales\n    C = K.shape[-1]\n    \n    # Producto de los tÃ©rminos a lo largo de la dimensiÃ³n F\n    product = tf.reduce_prod(K, axis=1)  # (N, C, C)\n    \n    # Calcular la traza de las matrices cuadradas\n    trace = tf.linalg.trace(product)\n    trace = tf.expand_dims(tf.expand_dims(trace, axis=-1), axis=-1)\n    trace = tf.tile(trace, [1, C, C])\n\n    # Normalizar el producto\n    argument = product / trace\n    argument = tf.expand_dims(argument, axis=1)  # Se necesita porque renyi_entropy recibe 4 dimensiones (1, C, C)\n    \n    # Calcular la entropÃ­a conjunta usando la funciÃ³n renyi_entropy\n    joint_entropy = renyi_entropy(argument, alpha=alpha)\n    \n    return joint_entropy\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.198451Z","iopub.execute_input":"2024-08-14T16:12:16.198832Z","iopub.status.idle":"2024-08-14T16:12:16.211724Z","shell.execute_reply.started":"2024-08-14T16:12:16.198797Z","shell.execute_reply":"2024-08-14T16:12:16.210763Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## **InformaciÃ³n mutua**\n\nLa informaciÃ³n mutua $\\alpha$-Renyi se calcula de la siguiente manera:\n\nDando un conjunto de kernels gaussianos $\\{\\tilde{\\mathbf{K}}_g\\}_{g=1}^{G}$:\n\n\\begin{equation}\\label{eq:MIRenyi}\nI_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g\\}_{g=1}^{G}\\right) = \\sum_{g=1}^G S_\\alpha(\\tilde{\\mathbf{K}}_g) - S_\\alpha\\left(\\frac{\\prod_{g=1}^G \\tilde{\\mathbf{K}}_g}{\\text{tr}\\left(\\prod_{g=1}^G \\tilde{\\mathbf{K}}_g\\right)}\\right). \n\\end{equation}\n\nY a partir de esta, construÃ­mos el loss que nos ayudarÃ¡ a regularizar:\n\n$$\\mathcal{L}_\\alpha(M)=I_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g(\\mathcal{M})\\}_{g=1}^{G}\\right)$$\n\ndonde $\\mathcal{M}$ es el modelo de deep learning. \n\nAdemÃ¡s, normalizamos la informaciÃ³n mutua de la siguiente manera:\n\nSabemos que $H_\\alpha(K)\\leq H_\\alpha(\\frac{1}{N}\\mathbf{I}) $ donde N es el tamaÃ±o del kernel cuadrado ($N\\times N$)\n\nPor lo tanto, \n\n\n\\begin{align}\nI_\\alpha(K_1, K_2, \\dots, K_F) &= \\sum_{f=1}^F H_\\alpha(K_f)-H_\\alpha\\left(K_1, K_2, \\dots, K_F\\right) \\\\\n                   &\\leq \\sum_{f=1}^F H_\\alpha(K_f) \\\\\n                   &\\leq \\sum_{f=1}^F H_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right) \\\\\n                   &\\leq F \\cdot H_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right)\n\\end{align}\n\n\nPor otro lado,\n\\begin{align*}\nH_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right)&= \\frac{1}{1-\\alpha}log\\left(tr\\left(\\frac{1}{N^\\alpha} \\mathbf{I} \\right)\\right)\\\\\n                                          &= \\frac{1}{1-\\alpha}log\\left(\\frac{N}{N^\\alpha} \\right)\\\\\n                                          &= \\frac{1}{1-\\alpha}log\\left(N^{1-\\alpha} \\right)\\\\\n                                          &= log(N)\n\\end{align*}\n\nPor lo tanto, podemos concluir que \n\n$$I_\\alpha(K_1, K_2, \\dots, K_F) \\leq F log(N)$$","metadata":{}},{"cell_type":"code","source":"class RenyiMutualInformation(Loss):\n    def __init__(self, C, **kwargs):\n        \"\"\"\n        Inicializa la clase RenyiMutualInformation.\n\n        ParÃ¡metros:\n        -----------\n        C : int o float\n            El nÃºmero de canales (dimensiÃ³n C) utilizado para la normalizaciÃ³n en el cÃ¡lculo de la informaciÃ³n mutua.\n        kwargs : dict\n            Otros argumentos opcionales que se pasan a la clase base `Loss`.\n        \"\"\"\n        self.C = C\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        Calcula la pÃ©rdida basada en la informaciÃ³n mutua de RÃ©nyi.\n\n        ParÃ¡metros:\n        -----------\n        y_true : Tensor\n            Etiquetas verdaderas, no se utilizan en este cÃ¡lculo de pÃ©rdida, pero se requieren para cumplir con la API de Keras.\n\n        y_pred : Tensor\n            Tensor de predicciones de forma `(N, F+1)`, donde:\n            - N: NÃºmero de muestras en el lote.\n            - F: NÃºmero de entropÃ­as marginales.\n            - F+1: La Ãºltima columna contiene la entropÃ­a conjunta.\n\n        Retorna:\n        --------\n        Tensor\n            Un tensor de pÃ©rdida de forma `(N, 1)`, que contiene la informaciÃ³n mutua de RÃ©nyi calculada para cada muestra.\n\n        DescripciÃ³n:\n        ------------\n        Esta clase implementa una pÃ©rdida basada en la informaciÃ³n mutua de RÃ©nyi, que es una medida de la cantidad de informaciÃ³n que comparten dos o mÃ¡s variables. En este caso, se utiliza para evaluar quÃ© tan bien las predicciones del modelo reflejan la dependencia entre diferentes caracterÃ­sticas.\n\n        Pasos:\n        ------\n        1. **SeparaciÃ³n de EntropÃ­as**:\n            - Se divide el tensor `y_pred` en dos partes: `entropy` que contiene las entropÃ­as marginales de cada caracterÃ­stica, y `joint_entropy` que contiene la entropÃ­a conjunta.\n\n        2. **Casteo de Tipos**:\n            - Se asegura de que tanto las entropÃ­as marginales como la entropÃ­a conjunta estÃ©n en formato `tf.float64` para una mayor precisiÃ³n en los cÃ¡lculos.\n\n        3. **CÃ¡lculo del Logaritmo de `C`**:\n            - Se calcula el logaritmo natural de `C` (`log_C`), que es un valor constante utilizado en la normalizaciÃ³n del cÃ¡lculo.\n\n        4. **CÃ¡lculo de la InformaciÃ³n Mutua de RÃ©nyi**:\n            - Se calcula la suma de las entropÃ­as marginales, se resta la entropÃ­a conjunta y se normaliza por `F * log_C` para obtener la informaciÃ³n mutua de RÃ©nyi normalizada.\n\n        Ejemplo de Uso:\n        ---------------\n        ```python\n        # Definir la pÃ©rdida en el modelo\n        model.compile(optimizer='adam', loss=[NormalizedBinaryCrossentropy(), RenyiMutualInformation(C=64)], loss_weights=[0.8, 0.2])\n        ```\n\n        Notas:\n        ------\n        - Esta clase estÃ¡ diseÃ±ada para trabajar en conjunto con un modelo que genere tanto las entropÃ­as marginales como la entropÃ­a conjunta como salidas.\n        - La informaciÃ³n mutua de RÃ©nyi es Ãºtil en tareas donde es importante evaluar la cantidad de informaciÃ³n compartida entre diferentes caracterÃ­sticas o seÃ±ales.\n        \"\"\"\n        \n        # NÃºmero de entropÃ­as marginales\n        F = y_pred.shape[1] - 1\n        \n        # Separar entropÃ­as marginales y entropÃ­a conjunta\n        entropy, joint_entropy = tf.split(y_pred, [F, 1], axis=-1)\n        \n        # Convertir a tf.float64\n        entropy = tf.cast(entropy, tf.float64)\n        joint_entropy = tf.cast(joint_entropy, tf.float64)\n        log_C = tf.math.log(tf.cast(self.C, tf.float64))\n        \n        # Calcular la informaciÃ³n mutua de RÃ©nyi\n        mutual_information = tf.math.abs(\n            (tf.expand_dims(tf.reduce_sum(entropy, axis=-1), axis=-1) - joint_entropy)\n        ) / (F * log_C)  # NormalizaciÃ³n\n\n        return mutual_information\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.213087Z","iopub.execute_input":"2024-08-14T16:12:16.213592Z","iopub.status.idle":"2024-08-14T16:12:16.229918Z","shell.execute_reply.started":"2024-08-14T16:12:16.213561Z","shell.execute_reply":"2024-08-14T16:12:16.229047Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Normalized cross-entropy**","metadata":{}},{"cell_type":"markdown","source":"AdemÃ¡s, para garantizar que la entropÃ­a cruzada tambiÃ©n estÃ© normalizada usamos la fÃ³rmula propuesta en [https://proceedings.mlr.press/v119/ma20c.html](http://)\n\n![image.png](attachment:8d0299cf-0448-4c8c-8929-80deb2e60210.png)","metadata":{},"attachments":{"8d0299cf-0448-4c8c-8929-80deb2e60210.png":{"image/png":"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"}}},{"cell_type":"code","source":"class NormalizedBinaryCrossentropy(Loss):\n    def __init__(self, **kwargs):\n        \"\"\"\n        Inicializa la clase NormalizedBinaryCrossentropy.\n\n        ParÃ¡metros:\n        -----------\n        kwargs : dict\n            Argumentos opcionales que se pasan a la clase base `Loss`.\n        \"\"\"\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        Calcula la pÃ©rdida de entropÃ­a cruzada binaria normalizada.\n\n        ParÃ¡metros:\n        -----------\n        y_true : Tensor\n            Tensor de etiquetas verdaderas de forma `(N, 2)`, donde:\n            - N: NÃºmero de muestras en el lote.\n            - 2: Corresponde a las clases binarias (0 o 1).\n\n        y_pred : Tensor\n            Tensor de predicciones de forma `(N, 2)`, donde:\n            - N: NÃºmero de muestras en el lote.\n            - 2: Predicciones de probabilidad para las dos clases binarias.\n\n        Retorna:\n        --------\n        Tensor\n            Un tensor de pÃ©rdida de forma `(N,)`, que contiene la pÃ©rdida de entropÃ­a cruzada binaria normalizada para cada muestra.\n\n        DescripciÃ³n:\n        ------------\n        Esta clase implementa una versiÃ³n normalizada de la pÃ©rdida de entropÃ­a cruzada binaria. La entropÃ­a cruzada binaria es una medida de la disimilitud entre dos distribuciones de probabilidad, a menudo utilizada como una funciÃ³n de pÃ©rdida en problemas de clasificaciÃ³n binaria.\n\n        En esta implementaciÃ³n, la pÃ©rdida de entropÃ­a cruzada se normaliza utilizando las pÃ©rdidas teÃ³ricas asociadas a las etiquetas `[1, 0]` y `[0, 1]`, que representan las dos clases posibles. La normalizaciÃ³n tiene como objetivo ajustar la pÃ©rdida para que sea mÃ¡s robusta frente a distribuciones de probabilidad sesgadas.\n\n        Pasos:\n        ------\n        1. **CÃ¡lculo de la EntropÃ­a Cruzada Binaria**:\n            - Se calcula la pÃ©rdida de entropÃ­a cruzada binaria estÃ¡ndar entre `y_true` y `y_pred`.\n\n        2. **CÃ¡lculo de la PÃ©rdida para Etiquetas TeÃ³ricas**:\n            - Se generan las pÃ©rdidas teÃ³ricas `cce_left` y `cce_right` utilizando las etiquetas `[1.0, 0.0]` y `[0.0, 1.0]` respectivamente.\n\n        3. **NormalizaciÃ³n**:\n            - La pÃ©rdida original se divide por la suma de las pÃ©rdidas teÃ³ricas, obteniendo asÃ­ una versiÃ³n normalizada de la pÃ©rdida.\n\n        Ejemplo de Uso:\n        ---------------\n        ```python\n        # Definir la pÃ©rdida en el modelo\n        model.compile(optimizer='adam', loss=NormalizedBinaryCrossentropy())\n        ```\n\n        Notas:\n        ------\n        - Esta pÃ©rdida es Ãºtil en casos donde se desea mitigar el impacto de clases desbalanceadas, ya que la normalizaciÃ³n ajusta la magnitud de la pÃ©rdida en funciÃ³n de las predicciones teÃ³ricas.\n        - La normalizaciÃ³n ayuda a hacer que el aprendizaje sea mÃ¡s estable y menos sensible a predicciones con alta confianza errÃ³nea.\n        \"\"\"\n        \n        # Obtener el tamaÃ±o del lote\n        batch_size = tf.shape(y_pred)[0]  \n        batch_size_float = tf.cast(batch_size, tf.float32)\n        \n        # Calcular la entropÃ­a cruzada binaria estÃ¡ndar\n        cce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n        \n        # Crear etiquetas teÃ³ricas para cada clase\n        left = tf.tile(tf.expand_dims([1.0, 0.0], axis=0), [batch_size, 1])\n        right = tf.tile(tf.expand_dims([0.0, 1.0], axis=0), [batch_size, 1])\n        \n        # Calcular la entropÃ­a cruzada binaria para las etiquetas teÃ³ricas\n        cce_left = tf.keras.losses.binary_crossentropy(left, y_pred)\n        cce_right = tf.keras.losses.binary_crossentropy(right, y_pred)\n        \n        # Normalizar la entropÃ­a cruzada binaria estÃ¡ndar\n        cce_norm = tf.divide(cce, (cce_left + cce_right))\n        \n        return cce_norm","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.231118Z","iopub.execute_input":"2024-08-14T16:12:16.231453Z","iopub.status.idle":"2024-08-14T16:12:16.247133Z","shell.execute_reply.started":"2024-08-14T16:12:16.231423Z","shell.execute_reply":"2024-08-14T16:12:16.246172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **Modelo GMRRNet**\n\nSe debe tener en cuenta que el loss total usado es la combinaciÃ³n de los dos anteriores:\n\n\\begin{equation}\\label{eq:GMRRloss}\n\\mathcal{L}(\\mathbf{y},\\hat{\\mathbf{y}}|\\mathcal{M}) = -\\lambda\\sum_{q=1}^Q y_q\\log(\\hat{y}_q(\\mathcal{M})) + (1-\\lambda) I_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g(\\mathcal{M})\\}_{g=1}^{G}\\right),\n\\end{equation}","metadata":{}},{"cell_type":"code","source":"def GMRRNet(nb_classes=2, Chans=64, Samples=320, \n                          kernLength=64, norm_rate=0.25, alpha=2): \n    \"\"\"\n    Construye un modelo de red neuronal convolucional basado en bloques de Inception con capas de convoluciÃ³n y cÃ¡lculo de entropÃ­a de Renyi.\n\n    ParÃ¡metros:\n    -----------\n    nb_classes : int, opcional (default=2)\n        NÃºmero de clases de salida para la clasificaciÃ³n.\n    \n    Chans : int, opcional (default=64)\n        NÃºmero de canales de entrada (dimensiÃ³n espacial).\n    \n    Samples : int, opcional (default=320)\n        NÃºmero de muestras de entrada (dimensiÃ³n temporal).\n    \n    kernLength : int, opcional (default=64)\n        Longitud del kernel para la primera capa convolucional.\n    \n    norm_rate : float, opcional (default=0.25)\n        Tasa de normalizaciÃ³n para la regularizaciÃ³n en capas densas.\n    \n    alpha : int, opcional (default=2)\n        ParÃ¡metro de orden para la entropÃ­a de Renyi, donde alpha=2 representa la entropÃ­a de Renyi cuadrÃ¡tica.\n\n    Retorna:\n    --------\n    model : tf.keras.Model\n        El modelo de red neuronal compilado listo para ser entrenado.\n    \n    DescripciÃ³n:\n    ------------\n    Esta funciÃ³n crea y compila un modelo de red neuronal convolucional con las siguientes caracterÃ­sticas:\n\n    1. **Entrada**:\n        - La entrada es un tensor de 4D de forma `(Chans, Samples, 1)`, donde `Chans` es el nÃºmero de canales (dimensiÃ³n espacial) y `Samples` es el nÃºmero de muestras (dimensiÃ³n temporal).\n\n    2. **Primera Capa Convolucional**:\n        - Una capa convolucional `Conv2D` con `F1=3` filtros y un kernel de longitud `kernLength=64`.\n\n    3. **Bloque de Inception**:\n        - Un bloque de Inception personalizado que aplica un filtro gaussiano con diferentes sigmas y pasa los resultados a una convoluciÃ³n `Conv2D`.\n        - Se utilizan tres sigmas diferentes: `sigma1=0.8`, `sigma2=2.2`, y `sigma3=4.8`.\n        - Se aplican tres convoluciones `Conv2D` con `F2=5` filtros cada una y se concatenan sus salidas.\n\n    4. **CÃ¡lculo de la EntropÃ­a de Renyi**:\n        - Las salidas de las capas de kernel gaussiano del bloque de Inception se concatenan y se calcula la entropÃ­a de Renyi marginal y conjunta usando la funciÃ³n `renyi_entropy` y `joint_renyi_entropy`, respectivamente.\n\n    5. **Capas Finales**:\n        - Se aÃ±ade otra capa convolucional `Conv2D` con `F3=3` filtros seguida de una capa de normalizaciÃ³n por lotes (`BatchNormalization`), aplanamiento (`Flatten`), y dos capas densas con una funciÃ³n de activaciÃ³n `softmax` para la salida final.\n\n    6. **CompilaciÃ³n del Modelo**:\n        - El modelo se compila con el optimizador `Adam`.\n        - Se utiliza una combinaciÃ³n de dos funciones de pÃ©rdida:\n            1. `NormalizedBinaryCrossentropy`: Una pÃ©rdida normalizada de entropÃ­a cruzada binaria.\n            2. `RenyiMutualInformation`: Una pÃ©rdida basada en la informaciÃ³n mutua de Renyi entre las entropÃ­as calculadas.\n        - Las pÃ©rdidas se ponderan con `loss_weights=[0.8, 0.2]`.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    model = GMRRNet(nb_classes=2, Chans=64, Samples=320, kernLength=64, norm_rate=0.25, alpha=2)\n    model.summary()\n    ```\n    \n    Notas:\n    ------\n    - Este modelo es adecuado para tareas de clasificaciÃ³n binaria o multi-clase donde es importante capturar relaciones complejas entre caracterÃ­sticas utilizando bloques de Inception.\n    - La inclusiÃ³n de la entropÃ­a de Renyi como una medida adicional puede mejorar la robustez del modelo en escenarios con incertidumbre.\n    \"\"\"\n    \n    ###### DefiniciÃ³n de los filtros para las capas convolucionales\n    F1 = 3\n    F2 = 5\n    F3 = 3\n    \n    ###### DefiniciÃ³n de la entrada\n    input1 = Input(shape=(Chans, Samples, 1))\n\n    ##################################################################\n    # Primera capa convolucional con normalizaciÃ³n por lotes\n    conv2D = Conv2D(F1, (1, kernLength), padding='same',\n                    name='Conv2D_1',\n                    input_shape=(Chans, Samples, 1),\n                    use_bias=False)(input1)\n    block1 = BatchNormalization()(conv2D)\n    \n    # DefiniciÃ³n de los sigmas para el bloque de Inception\n    sigma1 = 0.8\n    sigma2 = 2.2\n    sigma3 = 4.8\n\n    # Bloque de Inception\n    branch_k1, branch_k2, branch_k3, inception = inception_block(block1, [F2, F2, F2], [sigma1, sigma2, sigma3])\n    \n    ##############\n    \n    # ConcatenaciÃ³n de las ramas del bloque de Inception para el cÃ¡lculo de entropÃ­as\n    concatenated_branches = concatenate([branch_k1, branch_k2, branch_k3], axis=-1)\n    concatenated_branches = tf.transpose(concatenated_branches, perm=(0, 3, 1, 2))\n    layer_entropy = Lambda(lambda x: renyi_entropy(x, alpha=alpha), name=\"entropy\")(concatenated_branches)\n    \n    layer_joint_entropy = Lambda(lambda x: joint_renyi_entropy(x, alpha=alpha), name=\"joint_entropy\")(concatenated_branches)\n    \n    concatenate_entropies = concatenate([layer_entropy, layer_joint_entropy], axis=-1, name=\"concatenated_entropies\")\n    \n    ###############\n    # Segunda capa convolucional con normalizaciÃ³n por lotes y aplanamiento\n    conv2D = Conv2D(F3, 3, padding='same',\n                    name='Conv2D_2')(inception)\n    \n    conv2D = BatchNormalization()(conv2D)\n    flatten = Flatten(name='flatten')(conv2D)\n    \n    # Capas densas con activaciÃ³n y normalizaciÃ³n\n    dense = Dense(64, kernel_constraint=max_norm(norm_rate), activation=\"relu\")(flatten)\n    dense = Dense(nb_classes, name='output', \n                  kernel_constraint=max_norm(norm_rate))(dense)\n    softmax = Activation('softmax', name='out_activation')(dense)\n    \n    # CreaciÃ³n del modelo\n    model = Model(inputs=input1, outputs=[softmax, concatenate_entropies])    \n    \n    # CompilaciÃ³n del modelo\n    model.compile(optimizer='adam', \n                  loss=[NormalizedBinaryCrossentropy(), RenyiMutualInformation(C=tf.cast(64.0, tf.float64), name='MutualInfo')], \n                  loss_weights=[0.8, 0.2], \n                  metrics=[['binary_accuracy'], [None]])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.248668Z","iopub.execute_input":"2024-08-14T16:12:16.249068Z","iopub.status.idle":"2024-08-14T16:12:16.268094Z","shell.execute_reply.started":"2024-08-14T16:12:16.249035Z","shell.execute_reply":"2024-08-14T16:12:16.267290Z"},"trusted":true},"execution_count":12,"outputs":[]}]}