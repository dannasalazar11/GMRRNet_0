{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **GMRRNet funcions:** \n\nEste cuaderno documenta todas las funciones y clases utilizadas para el correcto y buen funcionamiento del modelo.","metadata":{}},{"cell_type":"markdown","source":"# **Instalamos lo necesario e importamos librerías**","metadata":{}},{"cell_type":"code","source":"!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-08-14T16:10:50.543949Z","iopub.execute_input":"2024-08-14T16:10:50.544265Z","iopub.status.idle":"2024-08-14T16:11:59.888622Z","shell.execute_reply.started":"2024-08-14T16:10:50.544236Z","shell.execute_reply":"2024-08-14T16:11:59.887362Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/UN-GCPDS/python-gcpds.databases\n  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-3tsee6eh\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-3tsee6eh\n  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit c35637e1a19d7cd21656496339c1dedae6714916\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.7.5)\nRequirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (1.7.1)\nRequirement already satisfied: tables in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (3.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (4.66.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gcpds-databases==0.2) (2.2.2)\nCollecting gdown (from gcpds-databases==0.2)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown->gcpds-databases==0.2) (2.32.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (3.1.2)\nRequirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (0.3)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne->gcpds-databases==0.2) (1.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->gcpds-databases==0.2) (2023.4)\nRequirement already satisfied: numexpr>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.10.1)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (9.0.0)\nRequirement already satisfied: blosc2>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from tables->gcpds-databases==0.2) (2.7.0)\nRequirement already satisfied: ndindex>=1.4 in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.8)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.0.7)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne->gcpds-databases==0.2) (3.11.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne->gcpds-databases==0.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: gcpds-databases\n  Building wheel for gcpds-databases (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=94504 sha256=c97b03346d976a26fc2c7ef2eb8975c507bfdc361b9bfd0eb954fb2359bc873e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k5ly5454/wheels/8e/66/a7/91b78b1787a3e4d17cb82ea2da67845aa9389012c0ed8280b0\nSuccessfully built gcpds-databases\nInstalling collected packages: gdown, gcpds-databases\nSuccessfully installed gcpds-databases-0.2 gdown-5.2.0\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models\n  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to /tmp/pip-req-build-zsx2f4i0\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models /tmp/pip-req-build-zsx2f4i0\n  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models to commit 975885b1f6814fd5958199919b33e02a6a9aa152\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\n  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\nCollecting moabb (from EEG_Tensorflow_models==0.2)\n  Downloading moabb-1.1.0-py3-none-any.whl.metadata (16 kB)\nCollecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow>=2.8 in /opt/conda/lib/python3.10/site-packages (from EEG_Tensorflow_models==0.2) (2.15.0)\nCollecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mne in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.7.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.11.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.10.0)\nCollecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading skorch-1.0.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=2.8->EEG_Tensorflow_models==0.2)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: PyYAML<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.1)\nCollecting coverage<8.0.0,>=7.0.1 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\nCollecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading edfio-0.4.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.61.0)\nCollecting mne-bids<0.15,>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading mne_bids-0.14-py2.py3-none-any.whl.metadata (4.8 kB)\nCollecting pandas (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\nCollecting pyriemann<0.7,>=0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pyriemann-0.6-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting pytest<8.0.0,>=7.4.0 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (2.32.3)\nCollecting scikit-learn>=1.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (4.66.4)\nRequirement already satisfied: urllib3<2.0.0,>=1.26.15 in /opt/conda/lib/python3.10/site-packages (from moabb->EEG_Tensorflow_models==0.2) (1.26.18)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (9.5.0)\nRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.14)\nRequirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.33.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.42.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (5.9.3)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (5.1.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.2)\nRequirement already satisfied: lazy-loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2023.3.post1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (3.11.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pyriemann<0.7,>=0.6->moabb->EEG_Tensorflow_models==0.2) (1.4.2)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest<8.0.0,>=7.4.0->moabb->EEG_Tensorflow_models==0.2) (2.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb->EEG_Tensorflow_models==0.2) (2024.7.4)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.4.2->moabb->EEG_Tensorflow_models==0.2) (3.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.3)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.2.2)\nDownloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading moabb-1.1.0-py3-none-any.whl (230 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.7/230.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.7/234.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading edfio-0.4.3-py3-none-any.whl (25 kB)\nDownloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mne_bids-0.14-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyriemann-0.6-py2.py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest-7.4.4-py3-none-any.whl (325 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading skorch-1.0.0-py3-none-any.whl (239 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\n  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29376 sha256=f551115b8d56f90d820c9adb4b98385c67d73f4152ac5c5c9750945b29337e5c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-l499e0a1/wheels/05/dc/8a/9d552a33fb901c0d7ab2a72746b5ea17643c570811c711d568\nSuccessfully built EEG_Tensorflow_models\nInstalling collected packages: typeguard, keras, edflib-python, edfio, coverage, tf-keras-vis, tensorflow-addons, scikit-learn, pytest, pandas, skorch, pyriemann, mne-bids, braindecode, moabb, EEG_Tensorflow_models\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.1.5\n    Uninstalling typeguard-4.1.5:\n      Successfully uninstalled typeguard-4.1.5\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pytest\n    Found existing installation: pytest 8.2.2\n    Uninstalling pytest-8.2.2:\n      Successfully uninstalled pytest-8.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.2\n    Uninstalling pandas-2.2.2:\n      Successfully uninstalled pandas-2.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ncudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-cudf 24.6.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.7 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2024.6.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nxarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 coverage-7.6.1 edfio-0.4.3 edflib-python-1.0.8 keras-2.15.0 mne-bids-0.14 moabb-1.1.0 pandas-1.5.3 pyriemann-0.6 pytest-7.4.4 scikit-learn-1.5.1 skorch-1.0.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from gcpds.databases import GIGA_MI_ME\nfrom typing import Optional, Sequence, Tuple\nimport matplotlib.pyplot as plt\nimport mne\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import  Input, Flatten, Dense, Activation, Dropout, concatenate, Layer, Conv2D, AveragePooling2D, SeparableConv2D, DepthwiseConv2D, BatchNormalization, SpatialDropout2D, Lambda\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.losses import Loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom keras_tuner import HyperModel, RandomSearch, Objective\nfrom IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:11:59.890598Z","iopub.execute_input":"2024-08-14T16:11:59.890899Z","iopub.status.idle":"2024-08-14T16:12:16.068053Z","shell.execute_reply.started":"2024-08-14T16:11:59.890870Z","shell.execute_reply":"2024-08-14T16:12:16.067272Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-14 16:12:05.400485: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-14 16:12:05.400593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-14 16:12:05.562731: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Función que carga la base de datos GIGA**\n\nRecuerde que es importante importar esta base de datos que se encuentra como \"giga-science-dataset\"","metadata":{}},{"cell_type":"code","source":"def load_GIGA(db: GIGA_MI_ME,\n              sbj: int,\n              eeg_ch_names: Sequence[str],\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    This function loads the GIGA-Science dataset locally.\n    \n    Parameters\n    ----------\n    db: GIGA_MI_ME\n        A GIGA_MI_ME object created by the gcpds.databases.GIGA_MI_ME module\n    sbj: int\n        The subject to load\n    eeg_ch_names: Sequence[str]\n        The EEG channel names in order\n    fs: float\n        The sampling frecuency\n    f_bank: np.ndarray\n        The frecuency range(s) to use\n    vwt: np.ndarray\n        The time window to load\n    new_fs: float\n        The new sampling frecuency to resample the data to\n    \n    Returns\n    ----------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing the EEG signals for each trial and the corresponding label\n    \n    Notes\n    ----------\n    The database description can be found here:\n    https://academic.oup.com/gigascience/article/6/7/gix034/3796323\n    \"\"\"\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    #print(np.mean (X), np.var(X))\n    return X, y\n\ndef butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n    \"\"\"\n    Apply digital butterworth filter\n    INPUT\n    ------\n    1. X: (D array)\n    array with signals.\n    2. N: (int+)\n    The order of the filter.\n    3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n    4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n    The type of filter\n    5. fs: (float+)\n    The sampling frequency of the digital system.\n    6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n    7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n    8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n    9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n    10. irlen: (int) or None, Default=nONE\n    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n    OUTPUT\n    ------\n    X_fil: (D array)\n    array with filtered signals.\n    \"\"\"\n    b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n    return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Time frequency representation of EEG signals.\n\n    Parameters\n    ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n    Methods\n    -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n    \"\"\"\n    def __init__(self, sfreq, f_bank=None, vwt=None):\n        self.sfreq = sfreq\n        self.f_bank = f_bank\n        self.vwt = vwt\n    # ------------------------------------------------------------------------------\n\n    def _validation_param(self):\n        \"\"\"\n        Validate Time-Frequency characterization parameters.\n        INPUT\n        -----\n          1. self\n        ------\n          2. None\n        \"\"\"\n        if self.sfreq <= 0:\n            raise ValueError('Non negative sampling frequency is accepted')\n\n\n        if self.f_bank is None:\n            self.flag_f_bank = False\n        elif self.f_bank.ndim != 2:\n            raise ValueError('Band frequencies have to be a 2D array')\n        else:\n            self.flag_f_bank = True\n\n        if self.vwt is None:\n            self.flag_vwt = False\n        elif self.vwt.ndim != 2:\n            raise ValueError('Time windows have to be a 2D array')\n        else:\n            self.flag_vwt = True\n\n    # ------------------------------------------------------------------------------\n    def _filter_bank(self, X):\n        \"\"\"\n        Filter bank Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n        \"\"\"\n        X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n        for f in np.arange(self.f_bank.shape[0]):\n            X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n        return X_f\n\n    # ------------------------------------------------------------------------------\n    def _sliding_windows(self, X):\n        \"\"\"\n        Sliding Windows Characterization.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n        OUTPUT\n        ------\n          1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n        \"\"\"\n        window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n        X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n        for w in np.arange(self.vwt.shape[0]):\n            X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n        return X_w\n\n    # ------------------------------------------------------------------------------\n    def fit(self, X, y=None):\n        \"\"\"\n        fit.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n          2. y: (1D array) target labels. Default=None\n        OUTPUT\n        ------\n          1. None\n        \"\"\"\n        pass\n\n    # ------------------------------------------------------------------------------\n    def transform(self, X, y=None):\n        \"\"\"\n        Time frequency representation of EEG signals.\n        INPUT\n        -----\n          1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n        OUTPUT\n        ------\n          1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n        \"\"\"\n        self._validation_param()     #Validate sfreq, f_freq, vwt\n\n        #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n        if self.flag_f_bank:\n            X_f = self._filter_bank(X)\n        else:\n            X_f = X[:,:,:,np.newaxis]\n\n        if self.flag_vwt:\n            X_wf = []\n            for f in range(X_f.shape[3]):\n                X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n            X_wf = np.stack(X_wf, axis=-1)\n        else:\n            X_wf = X_f[:,:,:,np.newaxis,:]\n        return X_wf\n    \ndef plot_training_history(history):\n    # Extraer datos de history\n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    train_out_activation_loss = history.history['out_activation_loss']\n    val_out_activation_loss = history.history['val_out_activation_loss']\n    train_concatenate_2_loss = history.history['concatenated_entropies_loss']\n    val_concatenate_2_loss = history.history['val_concatenated_entropies_loss']\n    train_out_activation_acc = history.history['out_activation_binary_accuracy']\n    val_out_activation_acc = history.history['val_out_activation_binary_accuracy']\n    epochs = range(1, len(train_loss) + 1)  # Número de épocas\n\n    # Graficar pérdida\n    plt.figure(figsize=(8, 4))\n    plt.plot(epochs, train_loss, 'b', label='Training total loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation total loss')\n    plt.plot(epochs, train_out_activation_loss, 'g', label='Training out_activation_loss')\n    plt.plot(epochs, val_out_activation_loss, 'm', label='Validation out_activation_loss')\n    plt.plot(epochs, train_concatenate_2_loss, 'y', label='Training concatenated_entropies_loss')\n    plt.plot(epochs, val_concatenate_2_loss, 'c', label='Validation concatenated_entropies_loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n    # Graficar precisión\n    plt.figure(figsize=(8, 4))\n    plt.plot(epochs, train_out_activation_acc, 'b', label='Training out_activation_binary_accuracy')\n    plt.plot(epochs, val_out_activation_acc, 'r', label='Validation out_activation_binary_accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.073289Z","iopub.execute_input":"2024-08-14T16:12:16.073648Z","iopub.status.idle":"2024-08-14T16:12:16.108290Z","shell.execute_reply.started":"2024-08-14T16:12:16.073623Z","shell.execute_reply":"2024-08-14T16:12:16.107373Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Gaussian Kernel Layer**\n\nEsta es una capa custom de keras para poder aplicar el kernel gaussiano en la red.\n","metadata":{}},{"cell_type":"code","source":"class GaussianKernelLayer(Layer):\n    \"\"\"\n    Capa personalizada de Keras que aplica un kernel Gaussiano sobre las entradas.\n\n    Esta capa calcula la distancia euclidiana al cuadrado entre pares de puntos y luego aplica una función kernel Gaussiana \n    para transformar esas distancias en similitudes, lo que es útil en el procesamiento de señales como EEG o en la construcción \n    de redes neuronales con funciones de kernel.\n\n    Parámetros:\n    -----------\n    sigma : float, opcional (por defecto=1.0)\n        Desviación estándar de la función kernel Gaussiana. Controla el alcance o \"spread\" de la Gaussiana.\n\n    Métodos:\n    --------\n    build(input_shape):\n        Método de construcción que inicializa los componentes internos de la capa basados en la forma de la entrada.\n    \n    call(inputs):\n        Método que aplica la transformación de la capa a las entradas.\n        \n        Parámetros:\n        -----------\n        inputs : Tensor\n            Tensor de entrada con la forma `(N, C, T, F)` donde:\n            - N: Número de muestras en el lote.\n            - C: Número de canales o características.\n            - T: Número de pasos temporales.\n            - F: Número de filtros.\n\n        Retorna:\n        --------\n        gaussian_kernel : Tensor\n            Tensor con la misma forma que el tensor de entrada, pero donde cada entrada ha sido transformada por el kernel Gaussiano.\n    \"\"\"\n\n    def __init__(self, sigma=1.0, **kwargs):\n        super(GaussianKernelLayer, self).__init__(**kwargs)\n        self.sigma = sigma\n\n    def build(self, input_shape):\n        \"\"\"\n        Inicializa la capa. Este método es llamado una sola vez y se utiliza para construir las variables de la capa.\n\n        Parámetros:\n        -----------\n        input_shape : tuple\n            Forma de la entrada esperada por la capa.\n        \"\"\"\n        super(GaussianKernelLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        \"\"\"\n        Aplica la transformación del kernel Gaussiano a los datos de entrada.\n\n        Parámetros:\n        -----------\n        inputs : Tensor\n            Tensor de entrada de forma `(N, C, T, F)`.\n\n        Retorna:\n        --------\n        gaussian_kernel : Tensor\n            Tensor de salida donde se ha aplicado el kernel Gaussiano, con forma `(N, C, C, F)`.\n        \"\"\"\n        # Descomposición de la forma del tensor de entrada\n        N, C, T, F = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n        \n        # Reorganizar el tensor de entrada a la forma (N*F, C, T)\n        inputs = tf.transpose(inputs, perm=(0, 3, 1, 2))  # Cambia la forma a (N, F, C, T)\n        inputs_reshaped = tf.reshape(inputs, (N * F, C, T))\n        \n        # Calcular la distancia euclidiana al cuadrado entre pares de puntos\n        squared_differences = tf.expand_dims(inputs_reshaped, axis=2) - tf.expand_dims(inputs_reshaped, axis=1)  # (N*F, C, C, T)\n        squared_differences = tf.square(squared_differences)  # (N*F, C, C, T)\n        pairwise_distances_squared = tf.reduce_sum(squared_differences, axis=-1)  # (N*F, C, C)\n        pairwise_distances_squared = tf.reshape(pairwise_distances_squared, (N, F, C, C))  # (N, F, C, C)\n        pairwise_distances_squared = tf.transpose(pairwise_distances_squared, perm=(0, 2, 3, 1))  # (N, C, C, F)\n        \n        # Calcular el kernel Gaussiano\n        gaussian_kernel = tf.exp(-pairwise_distances_squared / (2.0 * tf.square(self.sigma)))\n        \n        return gaussian_kernel\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.128453Z","iopub.execute_input":"2024-08-14T16:12:16.128831Z","iopub.status.idle":"2024-08-14T16:12:16.145020Z","shell.execute_reply.started":"2024-08-14T16:12:16.128798Z","shell.execute_reply":"2024-08-14T16:12:16.144154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Inception Block**\n\nEs el bloque donde se aplican 3 kernels gaussianos y cada uno seguido de una capa convolucional con un número específico de filtros.","metadata":{}},{"cell_type":"code","source":"def inception_block(x, filters, sigmas):\n    \"\"\"\n    Construye un bloque de Inception personalizado que incluye capas de convolución y capas de kernel Gaussiano.\n\n    Este bloque Inception crea tres ramas, cada una aplicando un kernel Gaussiano seguido de una capa de convolución 2D. \n    Finalmente, las salidas de estas ramas se concatenan a lo largo del eje de los canales.\n\n    Parámetros:\n    -----------\n    x : Tensor\n        Tensor de entrada con forma `(N, C, T, F)` donde:\n        - N: Número de muestras en el lote.\n        - C: Número de canales o características.\n        - T: Número de pasos temporales.\n        - F: Número de filtros o características adicionales.\n\n    filters : list of int\n        Lista que contiene el número de filtros para cada rama del bloque Inception. Debe ser una lista de tres enteros `[f1, f2, f3]` \n        donde `f1`, `f2`, y `f3` son el número de filtros para las ramas 1, 2 y 3 respectivamente.\n\n    sigmas : list of float\n        Lista que contiene los valores de `sigma` para cada capa `GaussianKernelLayer` en las ramas del bloque Inception. Debe ser una lista \n        de tres valores `[sigma1, sigma2, sigma3]` donde `sigma1`, `sigma2`, y `sigma3` corresponden a las ramas 1, 2 y 3 respectivamente.\n\n    Retorna:\n    --------\n    branch_k1, branch_k2, branch_k3 : Tensors\n        Las salidas de las capas `GaussianKernelLayer` en las tres ramas, con forma `(N, C, C, F)`.\n\n    output : Tensor\n        La salida concatenada de las tres ramas después de la capa de convolución, con forma `(N, C, T, f1 + f2 + f3)`.\n\n    Descripción:\n    ------------\n    Este bloque Inception se compone de las siguientes partes:\n    1. **Rama 1**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[0]` sobre la entrada `x`.\n        - Aplica una capa de convolución 2D con `f1` filtros de tamaño `(3, 3)` y activación `ReLU`.\n\n    2. **Rama 2**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[1]` sobre la entrada `x`.\n        - Aplica una capa de convolución 2D con `f2` filtros de tamaño `(3, 3)` y activación `ReLU`.\n\n    3. **Rama 3**:\n        - Aplica una capa `GaussianKernelLayer` con `sigma=sigmas[2]` sobre la entrada `x`.\n        - Aplica una capa de convolución 2D con `f3` filtros de tamaño `(3, 3)` y activación `ReLU`.\n\n    Finalmente, las salidas de las tres ramas se concatenan a lo largo del eje de los canales.\n    \"\"\"\n\n    # Filtros\n    f1, f2, f3 = filters\n\n    # Rama 1: Aplicar el kernel Gaussiano seguido de una convolución 2D\n    branch_k1 = GaussianKernelLayer(sigma=sigmas[0], name=\"gaussian_layer_1\")(x)\n    branch1 = Conv2D(f1, (3, 3), padding='same', activation='relu')(branch_k1)\n\n    # Rama 2: Aplicar el kernel Gaussiano seguido de una convolución 2D\n    branch_k2 = GaussianKernelLayer(sigma=sigmas[1], name=\"gaussian_layer_2\")(x)\n    branch2 = Conv2D(f2, (3, 3), padding='same', activation='relu')(branch_k2)\n\n    # Rama 3: Aplicar el kernel Gaussiano seguido de una convolución 2D\n    branch_k3 = GaussianKernelLayer(sigma=sigmas[2], name=\"gaussian_layer_3\")(x)\n    branch3 = Conv2D(f3, (3, 3), padding='same', activation='relu')(branch_k3)\n\n    # Concatenar las salidas de las tres ramas a lo largo del eje de los canales\n    output = concatenate([branch1, branch2, branch3], axis=-1)\n\n    return branch_k1, branch_k2, branch_k3, output\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.146333Z","iopub.execute_input":"2024-08-14T16:12:16.146894Z","iopub.status.idle":"2024-08-14T16:12:16.162003Z","shell.execute_reply.started":"2024-08-14T16:12:16.146869Z","shell.execute_reply":"2024-08-14T16:12:16.161094Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Información mutua - regularizador**\n\nPara calcular la información mutua, necesitamos de la entropia de Renyi y la entropía de Renyi conjunta. De modo que usamos esta para hacer que las salidas de los kernels compartan \"la menor información posible\" con el objetivo de calcular características diferentes.","metadata":{}},{"cell_type":"code","source":"class RenyiMutualInformation(Loss):\n    def __init__(self, C, **kwargs):\n        self.C = C\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        y_true: \n        y_pred: N x (F+1) las F entropías marginales y la entropía conjunta\n        \"\"\"\n        \n        F = y_pred.shape[1]-1\n        entropy,  joint_entropy = tf.split(y_pred, [F,1], axis=-1)\n        \n        #Cast todo\n        entropy = tf.cast(entropy, tf.float64)\n        joint_entropy = tf.cast(joint_entropy, tf.float64)\n        log_C = tf.math.log(tf.cast(self.C, tf.float64))\n        \n        mutual_information = tf.math.abs((tf.expand_dims(tf.reduce_sum(entropy, axis=-1), axis=-1) - joint_entropy)) / (F * log_C) # normalizado\n\n\n        return mutual_information","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.163091Z","iopub.execute_input":"2024-08-14T16:12:16.163339Z","iopub.status.idle":"2024-08-14T16:12:16.177336Z","shell.execute_reply.started":"2024-08-14T16:12:16.163311Z","shell.execute_reply":"2024-08-14T16:12:16.176529Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **Renyi Entropy**\n\nEsta función recibe un tensor y calcula la entropía de Renyi para esta teniendo en cuenta la siguiente fórmula:\n\n\\begin{equation}\\label{eq:renyiEntropy}\n    S_\\alpha(\\tilde{\\mathbf{K}})=\\frac{1}{1-\\alpha}\\log\\left(\\tilde{\\mathbf{K}}^\\alpha\\right),\n\\end{equation}\ndonde $\\alpha>0$, $\\alpha\\neq1$, $\\tilde{\\mathbf{K}}\\in \\mathbb{R}^{C \\times C}$ tiene los elementos del kernel gaussiano, y $\\text{tr}(\\tilde{\\mathbf{K}})=1.$\n\nSe debe normalizar este, por ende se divide por el producto de los elementos diagonales de sus matrices cuadradas","metadata":{}},{"cell_type":"code","source":"def renyi_entropy(K, alpha=2):\n    \"\"\"\n    Calcula la entropía de Rényi para un tensor de entrada.\n\n    Parámetros:\n    -----------\n    K : Tensor\n        Un tensor de entrada de forma `(N, F, C, C)`, donde:\n        - N: Número de muestras en el lote.\n        - F: Número de filtros o características.\n        - C: Número de canales o dimensiones de las matrices cuadradas dentro del tensor.\n\n    alpha : float, opcional\n        El parámetro de entropía de Rényi. Por defecto es 2.0.\n        - Cuando `alpha=2`, se aplica una optimización específica para este valor.\n\n    Retorna:\n    --------\n    Tensor\n        Un tensor de salida de forma `(N, F)`, que contiene la entropía de Rényi calculada para cada muestra y filtro.\n\n    Descripción:\n    ------------\n    La entropía de Rényi es una generalización de la entropía de Shannon, que depende de un parámetro `alpha`. Esta función \n    calcula la entropía de Rényi para cada una de las matrices cuadradas en el tensor `K` normalizado.\n\n    Pasos:\n    ------\n    1. **Normalización del Kernel**:\n        - Se normaliza el tensor `K` dividiéndolo por el producto de los elementos diagonales de sus matrices cuadradas.\n        - Esta normalización se realiza para estabilizar el cálculo de la entropía.\n\n    2. **Cálculo de la Entropía**:\n        - Si `alpha=2`, se utiliza una optimización que calcula la traza del producto matricial de `X` consigo mismo.\n        - Para otros valores de `alpha`, se calculan los autovalores de `X` y se utiliza la fórmula general para la entropía de Rényi.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    # Crear un tensor de ejemplo con la forma (N, F, C, C)\n    K = tf.random.normal((32, 10, 64, 64))\n\n    # Calcular la entropía de Rényi con alpha = 2\n    entropy = renyi_entropy(K, alpha=2)\n    print(entropy.shape)  # Salida: (32, 10)\n    ```\n\n    Notas:\n    ------\n    - La entropía de Rényi con `alpha=2` es especialmente útil en contextos donde se desea penalizar grandes concentraciones de probabilidad,\n      debido a que esta métrica es más sensible a distribuciones con pocos eventos de alta probabilidad.\n    - La función retorna la entropía negativa, lo que es estándar en la teoría de la información, ya que una mayor concentración \n      de probabilidad corresponde a una menor entropía.\n    \"\"\"\n\n    # Obtener el número de canales\n    C = K.shape[-1]\n\n    # Normalizamos el kernel antes de calcular la entropía\n\n    # Crear una máscara para obtener los elementos diagonales\n    diag = tf.expand_dims(tf.linalg.diag_part(K), -1)\n    # Calcular el producto de los elementos diagonales\n    denominator = tf.math.sqrt(tf.linalg.matmul(diag, diag, transpose_b=True))\n    # Normalización\n\n    X = (1/C) * tf.math.divide(K, denominator)\n    if alpha == 2:\n        # Realiza el producto matricial entre las dos últimas dimensiones\n        X_matmul = tf.linalg.matmul(X, X)\n        return -tf.math.log(tf.linalg.trace(X_matmul))\n    else:\n        # Calcula los autovalores y autovectores de las dos últimas dimensiones\n        e, _ = tf.linalg.eigh(X)\n        # Calcula la entropía de Renyi\n        return (tf.math.log(tf.reduce_sum(tf.math.real(tf.math.pow(e, alpha)), axis=-1)) / (1 - alpha))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.178627Z","iopub.execute_input":"2024-08-14T16:12:16.178898Z","iopub.status.idle":"2024-08-14T16:12:16.194906Z","shell.execute_reply.started":"2024-08-14T16:12:16.178875Z","shell.execute_reply":"2024-08-14T16:12:16.194022Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **Joint Renyi Entropy**\n\nCalculamos la entropía de $\\alpha$-Renyi conjunta de la siguiente manera:\n\n\\begin{equation}\\label{eq:jointREntropy}\n    S_\\alpha(\\tilde{\\mathbf{K}}_g, \\tilde{\\mathbf{K}}_{g'})=S_\\alpha\\left(\\frac{\\tilde{\\mathbf{K}}_g\\circ \\tilde{\\mathbf{K}}_{g'}}{\\text{tr}(\\tilde{\\mathbf{K}}_g\\circ \\tilde{\\mathbf{K}}_{g'})}\\right).\n\\end{equation} \n$\\circ$ es el producto de Hadamard.","metadata":{}},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"def joint_renyi_entropy(K, alpha):\n    \"\"\"\n    Calcula la entropía conjunta de Rényi para un tensor de entrada.\n\n    Parámetros:\n    -----------\n    K : Tensor\n        Un tensor de entrada de forma `(N, F, C, C)`, donde:\n        - N: Número de muestras en el lote.\n        - F: Número de filtros o características.\n        - C: Número de canales o dimensiones de las matrices cuadradas dentro del tensor.\n\n    alpha : float\n        El parámetro de entropía de Rényi. Controla la sensibilidad de la métrica a diferentes distribuciones de probabilidad.\n\n    Retorna:\n    --------\n    Tensor\n        Un tensor de salida de forma `(N, 1)`, que contiene la entropía conjunta de Rényi calculada para cada muestra.\n\n    Descripción:\n    ------------\n    Esta función calcula la entropía conjunta de Rényi, la cual mide la cantidad de incertidumbre en un sistema considerando múltiples variables conjuntamente. La entropía conjunta es útil para evaluar la dependencia o interrelación entre variables.\n\n    Pasos:\n    ------\n    1. **Producto de los Términos del Tensor**:\n        - Se realiza un producto a lo largo de la dimensión `F` del tensor `K`, reduciendo así el tensor de `(N, F, C, C)` a `(N, C, C)`.\n\n    2. **Cálculo de la Traza**:\n        - Se calcula la traza del tensor resultante, que es la suma de los elementos en la diagonal principal de las matrices cuadradas en `(N, C, C)`.\n        - La traza se expande y se repite para hacerla compatible con la dimensionalidad del tensor `K`.\n\n    3. **Normalización**:\n        - Se normaliza el producto obtenido en el primer paso dividiéndolo por la traza expandida, lo que estabiliza el cálculo de la entropía.\n\n    4. **Cálculo de la Entropía Conjunta**:\n        - Se pasa el tensor normalizado a la función `renyi_entropy`, que calcula la entropía de Rényi considerando la interrelación entre las variables.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    # Crear un tensor de ejemplo con la forma (N, F, C, C)\n    K = tf.random.normal((32, 10, 64, 64))\n\n    # Calcular la entropía conjunta de Rényi con alpha = 2\n    joint_entropy = joint_renyi_entropy(K, alpha=2)\n    print(joint_entropy.shape)  # Salida: (32, 1)\n    ```\n\n    Notas:\n    ------\n    - La entropía conjunta de Rényi es particularmente útil cuando se quiere evaluar la cantidad de información compartida entre múltiples variables.\n    - Al utilizar diferentes valores de `alpha`, se puede ajustar la sensibilidad de la métrica para enfatizar distribuciones de probabilidad más concentradas o más dispersas.\n    \"\"\"\n\n    # Obtener el número de canales\n    C = K.shape[-1]\n    \n    # Producto de los términos a lo largo de la dimensión F\n    product = tf.reduce_prod(K, axis=1)  # (N, C, C)\n    \n    # Calcular la traza de las matrices cuadradas\n    trace = tf.linalg.trace(product)\n    trace = tf.expand_dims(tf.expand_dims(trace, axis=-1), axis=-1)\n    trace = tf.tile(trace, [1, C, C])\n\n    # Normalizar el producto\n    argument = product / trace\n    argument = tf.expand_dims(argument, axis=1)  # Se necesita porque renyi_entropy recibe 4 dimensiones (1, C, C)\n    \n    # Calcular la entropía conjunta usando la función renyi_entropy\n    joint_entropy = renyi_entropy(argument, alpha=alpha)\n    \n    return joint_entropy\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.198451Z","iopub.execute_input":"2024-08-14T16:12:16.198832Z","iopub.status.idle":"2024-08-14T16:12:16.211724Z","shell.execute_reply.started":"2024-08-14T16:12:16.198797Z","shell.execute_reply":"2024-08-14T16:12:16.210763Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## **Información mutua**\n\nLa información mutua $\\alpha$-Renyi se calcula de la siguiente manera:\n\nDando un conjunto de kernels gaussianos $\\{\\tilde{\\mathbf{K}}_g\\}_{g=1}^{G}$:\n\n\\begin{equation}\\label{eq:MIRenyi}\nI_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g\\}_{g=1}^{G}\\right) = \\sum_{g=1}^G S_\\alpha(\\tilde{\\mathbf{K}}_g) - S_\\alpha\\left(\\frac{\\prod_{g=1}^G \\tilde{\\mathbf{K}}_g}{\\text{tr}\\left(\\prod_{g=1}^G \\tilde{\\mathbf{K}}_g\\right)}\\right). \n\\end{equation}\n\nY a partir de esta, construímos el loss que nos ayudará a regularizar:\n\n$$\\mathcal{L}_\\alpha(M)=I_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g(\\mathcal{M})\\}_{g=1}^{G}\\right)$$\n\ndonde $\\mathcal{M}$ es el modelo de deep learning. \n\nAdemás, normalizamos la información mutua de la siguiente manera:\n\nSabemos que $H_\\alpha(K)\\leq H_\\alpha(\\frac{1}{N}\\mathbf{I}) $ donde N es el tamaño del kernel cuadrado ($N\\times N$)\n\nPor lo tanto, \n\n\n\\begin{align}\nI_\\alpha(K_1, K_2, \\dots, K_F) &= \\sum_{f=1}^F H_\\alpha(K_f)-H_\\alpha\\left(K_1, K_2, \\dots, K_F\\right) \\\\\n                   &\\leq \\sum_{f=1}^F H_\\alpha(K_f) \\\\\n                   &\\leq \\sum_{f=1}^F H_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right) \\\\\n                   &\\leq F \\cdot H_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right)\n\\end{align}\n\n\nPor otro lado,\n\\begin{align*}\nH_\\alpha\\left(\\frac{1}{N}\\mathbf{I}\\right)&= \\frac{1}{1-\\alpha}log\\left(tr\\left(\\frac{1}{N^\\alpha} \\mathbf{I} \\right)\\right)\\\\\n                                          &= \\frac{1}{1-\\alpha}log\\left(\\frac{N}{N^\\alpha} \\right)\\\\\n                                          &= \\frac{1}{1-\\alpha}log\\left(N^{1-\\alpha} \\right)\\\\\n                                          &= log(N)\n\\end{align*}\n\nPor lo tanto, podemos concluir que \n\n$$I_\\alpha(K_1, K_2, \\dots, K_F) \\leq F log(N)$$","metadata":{}},{"cell_type":"code","source":"class RenyiMutualInformation(Loss):\n    def __init__(self, C, **kwargs):\n        \"\"\"\n        Inicializa la clase RenyiMutualInformation.\n\n        Parámetros:\n        -----------\n        C : int o float\n            El número de canales (dimensión C) utilizado para la normalización en el cálculo de la información mutua.\n        kwargs : dict\n            Otros argumentos opcionales que se pasan a la clase base `Loss`.\n        \"\"\"\n        self.C = C\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        Calcula la pérdida basada en la información mutua de Rényi.\n\n        Parámetros:\n        -----------\n        y_true : Tensor\n            Etiquetas verdaderas, no se utilizan en este cálculo de pérdida, pero se requieren para cumplir con la API de Keras.\n\n        y_pred : Tensor\n            Tensor de predicciones de forma `(N, F+1)`, donde:\n            - N: Número de muestras en el lote.\n            - F: Número de entropías marginales.\n            - F+1: La última columna contiene la entropía conjunta.\n\n        Retorna:\n        --------\n        Tensor\n            Un tensor de pérdida de forma `(N, 1)`, que contiene la información mutua de Rényi calculada para cada muestra.\n\n        Descripción:\n        ------------\n        Esta clase implementa una pérdida basada en la información mutua de Rényi, que es una medida de la cantidad de información que comparten dos o más variables. En este caso, se utiliza para evaluar qué tan bien las predicciones del modelo reflejan la dependencia entre diferentes características.\n\n        Pasos:\n        ------\n        1. **Separación de Entropías**:\n            - Se divide el tensor `y_pred` en dos partes: `entropy` que contiene las entropías marginales de cada característica, y `joint_entropy` que contiene la entropía conjunta.\n\n        2. **Casteo de Tipos**:\n            - Se asegura de que tanto las entropías marginales como la entropía conjunta estén en formato `tf.float64` para una mayor precisión en los cálculos.\n\n        3. **Cálculo del Logaritmo de `C`**:\n            - Se calcula el logaritmo natural de `C` (`log_C`), que es un valor constante utilizado en la normalización del cálculo.\n\n        4. **Cálculo de la Información Mutua de Rényi**:\n            - Se calcula la suma de las entropías marginales, se resta la entropía conjunta y se normaliza por `F * log_C` para obtener la información mutua de Rényi normalizada.\n\n        Ejemplo de Uso:\n        ---------------\n        ```python\n        # Definir la pérdida en el modelo\n        model.compile(optimizer='adam', loss=[NormalizedBinaryCrossentropy(), RenyiMutualInformation(C=64)], loss_weights=[0.8, 0.2])\n        ```\n\n        Notas:\n        ------\n        - Esta clase está diseñada para trabajar en conjunto con un modelo que genere tanto las entropías marginales como la entropía conjunta como salidas.\n        - La información mutua de Rényi es útil en tareas donde es importante evaluar la cantidad de información compartida entre diferentes características o señales.\n        \"\"\"\n        \n        # Número de entropías marginales\n        F = y_pred.shape[1] - 1\n        \n        # Separar entropías marginales y entropía conjunta\n        entropy, joint_entropy = tf.split(y_pred, [F, 1], axis=-1)\n        \n        # Convertir a tf.float64\n        entropy = tf.cast(entropy, tf.float64)\n        joint_entropy = tf.cast(joint_entropy, tf.float64)\n        log_C = tf.math.log(tf.cast(self.C, tf.float64))\n        \n        # Calcular la información mutua de Rényi\n        mutual_information = tf.math.abs(\n            (tf.expand_dims(tf.reduce_sum(entropy, axis=-1), axis=-1) - joint_entropy)\n        ) / (F * log_C)  # Normalización\n\n        return mutual_information\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.213087Z","iopub.execute_input":"2024-08-14T16:12:16.213592Z","iopub.status.idle":"2024-08-14T16:12:16.229918Z","shell.execute_reply.started":"2024-08-14T16:12:16.213561Z","shell.execute_reply":"2024-08-14T16:12:16.229047Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **Normalized cross-entropy**","metadata":{}},{"cell_type":"markdown","source":"Además, para garantizar que la entropía cruzada también esté normalizada usamos la fórmula propuesta en [https://proceedings.mlr.press/v119/ma20c.html](http://)\n\n![image.png](attachment:8d0299cf-0448-4c8c-8929-80deb2e60210.png)","metadata":{},"attachments":{"8d0299cf-0448-4c8c-8929-80deb2e60210.png":{"image/png":"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"}}},{"cell_type":"code","source":"class NormalizedBinaryCrossentropy(Loss):\n    def __init__(self, **kwargs):\n        \"\"\"\n        Inicializa la clase NormalizedBinaryCrossentropy.\n\n        Parámetros:\n        -----------\n        kwargs : dict\n            Argumentos opcionales que se pasan a la clase base `Loss`.\n        \"\"\"\n        super().__init__(**kwargs)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        Calcula la pérdida de entropía cruzada binaria normalizada.\n\n        Parámetros:\n        -----------\n        y_true : Tensor\n            Tensor de etiquetas verdaderas de forma `(N, 2)`, donde:\n            - N: Número de muestras en el lote.\n            - 2: Corresponde a las clases binarias (0 o 1).\n\n        y_pred : Tensor\n            Tensor de predicciones de forma `(N, 2)`, donde:\n            - N: Número de muestras en el lote.\n            - 2: Predicciones de probabilidad para las dos clases binarias.\n\n        Retorna:\n        --------\n        Tensor\n            Un tensor de pérdida de forma `(N,)`, que contiene la pérdida de entropía cruzada binaria normalizada para cada muestra.\n\n        Descripción:\n        ------------\n        Esta clase implementa una versión normalizada de la pérdida de entropía cruzada binaria. La entropía cruzada binaria es una medida de la disimilitud entre dos distribuciones de probabilidad, a menudo utilizada como una función de pérdida en problemas de clasificación binaria.\n\n        En esta implementación, la pérdida de entropía cruzada se normaliza utilizando las pérdidas teóricas asociadas a las etiquetas `[1, 0]` y `[0, 1]`, que representan las dos clases posibles. La normalización tiene como objetivo ajustar la pérdida para que sea más robusta frente a distribuciones de probabilidad sesgadas.\n\n        Pasos:\n        ------\n        1. **Cálculo de la Entropía Cruzada Binaria**:\n            - Se calcula la pérdida de entropía cruzada binaria estándar entre `y_true` y `y_pred`.\n\n        2. **Cálculo de la Pérdida para Etiquetas Teóricas**:\n            - Se generan las pérdidas teóricas `cce_left` y `cce_right` utilizando las etiquetas `[1.0, 0.0]` y `[0.0, 1.0]` respectivamente.\n\n        3. **Normalización**:\n            - La pérdida original se divide por la suma de las pérdidas teóricas, obteniendo así una versión normalizada de la pérdida.\n\n        Ejemplo de Uso:\n        ---------------\n        ```python\n        # Definir la pérdida en el modelo\n        model.compile(optimizer='adam', loss=NormalizedBinaryCrossentropy())\n        ```\n\n        Notas:\n        ------\n        - Esta pérdida es útil en casos donde se desea mitigar el impacto de clases desbalanceadas, ya que la normalización ajusta la magnitud de la pérdida en función de las predicciones teóricas.\n        - La normalización ayuda a hacer que el aprendizaje sea más estable y menos sensible a predicciones con alta confianza errónea.\n        \"\"\"\n        \n        # Obtener el tamaño del lote\n        batch_size = tf.shape(y_pred)[0]  \n        batch_size_float = tf.cast(batch_size, tf.float32)\n        \n        # Calcular la entropía cruzada binaria estándar\n        cce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n        \n        # Crear etiquetas teóricas para cada clase\n        left = tf.tile(tf.expand_dims([1.0, 0.0], axis=0), [batch_size, 1])\n        right = tf.tile(tf.expand_dims([0.0, 1.0], axis=0), [batch_size, 1])\n        \n        # Calcular la entropía cruzada binaria para las etiquetas teóricas\n        cce_left = tf.keras.losses.binary_crossentropy(left, y_pred)\n        cce_right = tf.keras.losses.binary_crossentropy(right, y_pred)\n        \n        # Normalizar la entropía cruzada binaria estándar\n        cce_norm = tf.divide(cce, (cce_left + cce_right))\n        \n        return cce_norm","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.231118Z","iopub.execute_input":"2024-08-14T16:12:16.231453Z","iopub.status.idle":"2024-08-14T16:12:16.247133Z","shell.execute_reply.started":"2024-08-14T16:12:16.231423Z","shell.execute_reply":"2024-08-14T16:12:16.246172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# **Modelo GMRRNet**\n\nSe debe tener en cuenta que el loss total usado es la combinación de los dos anteriores:\n\n\\begin{equation}\\label{eq:GMRRloss}\n\\mathcal{L}(\\mathbf{y},\\hat{\\mathbf{y}}|\\mathcal{M}) = -\\lambda\\sum_{q=1}^Q y_q\\log(\\hat{y}_q(\\mathcal{M})) + (1-\\lambda) I_\\alpha\\left(\\{\\tilde{\\mathbf{K}}_g(\\mathcal{M})\\}_{g=1}^{G}\\right),\n\\end{equation}","metadata":{}},{"cell_type":"code","source":"def GMRRNet(nb_classes=2, Chans=64, Samples=320, \n                          kernLength=64, norm_rate=0.25, alpha=2): \n    \"\"\"\n    Construye un modelo de red neuronal convolucional basado en bloques de Inception con capas de convolución y cálculo de entropía de Renyi.\n\n    Parámetros:\n    -----------\n    nb_classes : int, opcional (default=2)\n        Número de clases de salida para la clasificación.\n    \n    Chans : int, opcional (default=64)\n        Número de canales de entrada (dimensión espacial).\n    \n    Samples : int, opcional (default=320)\n        Número de muestras de entrada (dimensión temporal).\n    \n    kernLength : int, opcional (default=64)\n        Longitud del kernel para la primera capa convolucional.\n    \n    norm_rate : float, opcional (default=0.25)\n        Tasa de normalización para la regularización en capas densas.\n    \n    alpha : int, opcional (default=2)\n        Parámetro de orden para la entropía de Renyi, donde alpha=2 representa la entropía de Renyi cuadrática.\n\n    Retorna:\n    --------\n    model : tf.keras.Model\n        El modelo de red neuronal compilado listo para ser entrenado.\n    \n    Descripción:\n    ------------\n    Esta función crea y compila un modelo de red neuronal convolucional con las siguientes características:\n\n    1. **Entrada**:\n        - La entrada es un tensor de 4D de forma `(Chans, Samples, 1)`, donde `Chans` es el número de canales (dimensión espacial) y `Samples` es el número de muestras (dimensión temporal).\n\n    2. **Primera Capa Convolucional**:\n        - Una capa convolucional `Conv2D` con `F1=3` filtros y un kernel de longitud `kernLength=64`.\n\n    3. **Bloque de Inception**:\n        - Un bloque de Inception personalizado que aplica un filtro gaussiano con diferentes sigmas y pasa los resultados a una convolución `Conv2D`.\n        - Se utilizan tres sigmas diferentes: `sigma1=0.8`, `sigma2=2.2`, y `sigma3=4.8`.\n        - Se aplican tres convoluciones `Conv2D` con `F2=5` filtros cada una y se concatenan sus salidas.\n\n    4. **Cálculo de la Entropía de Renyi**:\n        - Las salidas de las capas de kernel gaussiano del bloque de Inception se concatenan y se calcula la entropía de Renyi marginal y conjunta usando la función `renyi_entropy` y `joint_renyi_entropy`, respectivamente.\n\n    5. **Capas Finales**:\n        - Se añade otra capa convolucional `Conv2D` con `F3=3` filtros seguida de una capa de normalización por lotes (`BatchNormalization`), aplanamiento (`Flatten`), y dos capas densas con una función de activación `softmax` para la salida final.\n\n    6. **Compilación del Modelo**:\n        - El modelo se compila con el optimizador `Adam`.\n        - Se utiliza una combinación de dos funciones de pérdida:\n            1. `NormalizedBinaryCrossentropy`: Una pérdida normalizada de entropía cruzada binaria.\n            2. `RenyiMutualInformation`: Una pérdida basada en la información mutua de Renyi entre las entropías calculadas.\n        - Las pérdidas se ponderan con `loss_weights=[0.8, 0.2]`.\n\n    Ejemplo de Uso:\n    ---------------\n    ```python\n    model = GMRRNet(nb_classes=2, Chans=64, Samples=320, kernLength=64, norm_rate=0.25, alpha=2)\n    model.summary()\n    ```\n    \n    Notas:\n    ------\n    - Este modelo es adecuado para tareas de clasificación binaria o multi-clase donde es importante capturar relaciones complejas entre características utilizando bloques de Inception.\n    - La inclusión de la entropía de Renyi como una medida adicional puede mejorar la robustez del modelo en escenarios con incertidumbre.\n    \"\"\"\n    \n    ###### Definición de los filtros para las capas convolucionales\n    F1 = 3\n    F2 = 5\n    F3 = 3\n    \n    ###### Definición de la entrada\n    input1 = Input(shape=(Chans, Samples, 1))\n\n    ##################################################################\n    # Primera capa convolucional con normalización por lotes\n    conv2D = Conv2D(F1, (1, kernLength), padding='same',\n                    name='Conv2D_1',\n                    input_shape=(Chans, Samples, 1),\n                    use_bias=False)(input1)\n    block1 = BatchNormalization()(conv2D)\n    \n    # Definición de los sigmas para el bloque de Inception\n    sigma1 = 0.8\n    sigma2 = 2.2\n    sigma3 = 4.8\n\n    # Bloque de Inception\n    branch_k1, branch_k2, branch_k3, inception = inception_block(block1, [F2, F2, F2], [sigma1, sigma2, sigma3])\n    \n    ##############\n    \n    # Concatenación de las ramas del bloque de Inception para el cálculo de entropías\n    concatenated_branches = concatenate([branch_k1, branch_k2, branch_k3], axis=-1)\n    concatenated_branches = tf.transpose(concatenated_branches, perm=(0, 3, 1, 2))\n    layer_entropy = Lambda(lambda x: renyi_entropy(x, alpha=alpha), name=\"entropy\")(concatenated_branches)\n    \n    layer_joint_entropy = Lambda(lambda x: joint_renyi_entropy(x, alpha=alpha), name=\"joint_entropy\")(concatenated_branches)\n    \n    concatenate_entropies = concatenate([layer_entropy, layer_joint_entropy], axis=-1, name=\"concatenated_entropies\")\n    \n    ###############\n    # Segunda capa convolucional con normalización por lotes y aplanamiento\n    conv2D = Conv2D(F3, 3, padding='same',\n                    name='Conv2D_2')(inception)\n    \n    conv2D = BatchNormalization()(conv2D)\n    flatten = Flatten(name='flatten')(conv2D)\n    \n    # Capas densas con activación y normalización\n    dense = Dense(64, kernel_constraint=max_norm(norm_rate), activation=\"relu\")(flatten)\n    dense = Dense(nb_classes, name='output', \n                  kernel_constraint=max_norm(norm_rate))(dense)\n    softmax = Activation('softmax', name='out_activation')(dense)\n    \n    # Creación del modelo\n    model = Model(inputs=input1, outputs=[softmax, concatenate_entropies])    \n    \n    # Compilación del modelo\n    model.compile(optimizer='adam', \n                  loss=[NormalizedBinaryCrossentropy(), RenyiMutualInformation(C=tf.cast(64.0, tf.float64), name='MutualInfo')], \n                  loss_weights=[0.8, 0.2], \n                  metrics=[['binary_accuracy'], [None]])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:12:16.248668Z","iopub.execute_input":"2024-08-14T16:12:16.249068Z","iopub.status.idle":"2024-08-14T16:12:16.268094Z","shell.execute_reply.started":"2024-08-14T16:12:16.249035Z","shell.execute_reply":"2024-08-14T16:12:16.267290Z"},"trusted":true},"execution_count":12,"outputs":[]}]}